https://www.youtube.com/watch?v=qWDi9I2Tmmk

Transcript - "50% Of Jobs Will Be Displaced" - Terrifying Future of AI If We're NOT Careful | Emad Mostaque


Search in video
Intro
0:00
today we're going deep into a conversation that has me incredibly fired up we're talking about our future
0:06
your future my future the future of humanity itself and we're doing it with one of the most Visionary Minds in
0:12
artificial intelligence emod moac and we were like it's coming for Hollywood you're in Los Angeles right yep is there
0:19
anyone in Hollywood that doesn't realize that they're coming yes there still is any here will there be anyone no emod is
0:26
a guy who's right at that edge building AI models that are TR truly shaping the future as AI becomes more integrated
0:33
into our lives we've got to ask a very important question how do we navigate this without losing what makes us human
0:39
how do you think that AI is going to impact democracy I think voice is the most impactful thing in terms of impact
0:46
negatively on Democracy okay so Trump kissing Putin we can make that in two seconds right it's not going to change
0:52
your mind whereas a recording of Oprah and the Rock saying how Mara Harris's
1:01
nasty things that shared on WhatsApp voice recording probably would actually have a much bigger impact out further
1:08
Ado I bring you emod [Music]
1:13
moac what percentage of the world's population do you think robots and AI
Robots and AI
1:19
are going to replace technically we seen you dying out by not repopulating anyway so maybe we'll end up all AI um but in
1:25
terms of the jobs to be done I think that was it open AI along with the MIT
1:31
did a study of this probably 50% of all tasks minimum as we have them today in
1:37
the next couple of decades and that's kind of a bit constrained by how fast we can build robots how fast can manual I
1:45
said we make like 80 million cars 70 million motorcycles I'd say probably in five years we're up to that pace in robots maybe more I mean like there's
1:53
been a lot of discussions around China AGI and we must compete with them you really want to compete in them and
1:59
robots to honest you think we need to make that a
Geost strategically
2:05
mission well geost strategically robots in the economy will
2:11
have as big like there's this let's say that this is division AGI super
2:16
intelligence you know that's one thing let's put that in its own box again how many chefs do you need versus how many
2:22
cooks do you need what do you need for human super human breakthroughs just living your life and being better and
2:29
executing well right there are all the digital AIS but
2:35
again everything seems to be saturated and open sources caught up with close Source Etc but then physical
2:42
robots once you get a robot you're not going to get another one whereas I can switch from one
2:48
digital AI to another so if I'm thinking of geost strategically these robots will perate
2:54
every part of society where they coming from if it's China I'm probably more worried about that geost strategically than I am
3:00
AGI or kind of whatever else because they're inevitable again you look at the cost
3:06
you look at the Quality you'll see with the latest Optimus one again look at the unitri G1 look at the figuro 2 they're
3:12
really good now and they will cost 10,000 they'll cost 100 bucks on Mon and it's inevitable the wave coming
3:19
and where are they going to be made whose intelligence they going to have on them I think that is a very
3:25
important point you know because again most human tasks are still physic
3:30
they're not digital we have to say that anything that you can do on the other side of a computer how can you tell a computer from a human now it's really
3:38
tough like I've seen some of the things like now with the video models the
3:44
speech models and everything they're all real time so like I could be an AI Avatar
3:50
with a level of technology that we have I'm not he says you wouldn't be able to tell the difference right now and so
3:57
again with all the mannerism it just get better and better and better I think eventually and I think this is what the study said 50% at least um how
How rapidly will call center jobs be replaced
4:04
rapidly were those the 50% of Tas that are going to get replaced how rapidly is that going to
4:11
happen why do you need any call center workers next year incremental
4:17
highes like again if you use a c head to AI can't really tell it from a human now
4:23
so we look at it and we look industry by industry first you stop offshor right
4:30
then you stop graduate hiring and then it impacts the workers until then there's a race condition whereby you're
4:37
just trying to have increased productivity lower costs it depends on the economic cycle as well but we're already seeing um I think month or two
4:44
ago I saw that 38% of the current IIT batch in India so IIT is like the top
4:50
Technological University in India still don't have job basements if you're in the Philippines what's happening to your
4:56
entire call center industry when you have a 24/7 AI that
5:01
speaks perfect English and is really calm and everything
5:07
right so I think it depends on by industry and it's difficult to tell because again different Industries will have different adoption curves but I
5:14
think anything that's outsourced right now that has to be in danger because
5:20
outsourced work tends to be lower quality right then you've not low quality it tends to be more content
5:25
creation shall we say like rot stuff then it's The Graduate level labor and
5:30
then it's specialized labor and the question is does new stuff emerge on the other
5:35
side well it's interesting because I would say specialized labor is also um
How disruptive will it be
5:41
because you can train an AI to do something if it's hyp specific as long as it doesn't need to be embodied um
5:47
okay this feels like it would be disruptive at any time but right now certainly here in America we're adding a
5:53
trillion dollars in debt every 90 days 90 to 100 uh the economy is soft now I'm
5:59
giving you gut instinct I think we're probably already in the middle of a recession that has simply been
6:05
redefined uh so there's a sense already of malaise certainly in young people job
6:11
market feels soft as somebody who does hiring I feel I'm back in the position
6:17
uh let's call it 18 months 24 months ago I very much felt like it was uh an
6:22
employee market and now feels like an owner Market um so add on top of that
6:28
the fact that this is going to be Happening Now how disruptive do you think this is going to be to the economy
6:33
are we going to find ourselves um making up for the all the crazy debt and
At the cost of human malaise
6:40
printing by this increased productivity through Ai and robots but at the cost of human malaise or how do you see that
6:47
playing out Limon tough to figure out isn't it like again it's the order of these
6:54
things so it's industry by industry like you know we talked uh whe last podcast
7:00
were just over a year ago yeah and we were like it's coming for Hollywood you're in Los Angeles right yep is there
7:07
anyone in hollyw that doesn't realize the coming yes there still is in year will there be anyone
7:12
no and you look at the SAG afro and other deals and they're awful like not awful but they don't protect the
7:20
industry employees as they should and so the cost of movies is
7:25
about to drop by an order of magnitude roughly but then what does that do to employment
7:31
in that particular industry when you have full control over every aspect of
7:37
the entire production process digitally but when does that happen a
7:43
couple of years you know whereas something like replacing uh truck
7:48
drivers in America millions of people employed on the city to City stuff maybe
7:54
10 years because you know like again
8:00
how are they going to retrain what are they going to do but I think it comes in wayes it's just very difficult to tell aggregate because there's a question
8:07
what doesn't this impact your hairdresser and again I think McKenzie or someone did a study of what doesn't
8:12
it impact there's very few things it doesn't impact especially with the embodied side and the embodied side again is going to ramp up as
8:19
aggressively as we've seen in the GPU side GPU side like you've had 10
8:24
hundreds of billions of dollars of investment now on these data centers and supercomputers and Donald Trump's talking about how the US already has
8:31
half the energy it needs so we should build more nuclear reactors and we like the air so because there's a imperative
8:38
to bring on board the digital technology and it's getting basically free and then
8:44
there'll be this physical and body technology it all depend on how fast We R that and then like industry to Industry is just different like a
8:51
specialized example paralegals every lawyer I've talked to senior lawyers like well we need less
8:56
par legals now well of course you just need to have one power legal to organize your AIS
9:04
right all right let me paint a picture for you let me know what you think about this so um the way that I think that
9:11
this is going to play out is um you're going to see a softening of
A softening of the job market
9:17
the job market that on top of all the money printing we've already done you're going to run into a problem so you're
9:23
not going to be able to print your way out of this or if they're that stupid and they try then you're going to really
9:29
run to inflation but let's assume that they don't make that stupid mistake so you see a softening of the job market
9:35
you're going to see people wanting to make big asks of the government to make things better because they they're not
9:41
feeling good they feel hopeless they feel lost uh that's demagogue territory somebody that comes in tells you why
9:47
your life sucks tells you how they're going to make it better uh problem is that because of all the Deep fakes
9:53
they're going to um interfere with the election people are not going to be able to tell what's real what's not real um
10:01
and now you're going to have both a populace that wants something desperately from their government and
10:07
they're not going to realize the depths to which they're being manipulated and
10:13
people already believe that the game is rigged neither side is going to believe
10:19
the election here in America uh so this feels like this perfect storm of AI hit
10:25
deep fake before we have put constraints in it to tell us what's real and what's not um right at this really critical
10:33
election I have a feeling um I will be surprised if there aren't
Pockets of violence
10:41
pockets of violence a at or after the election I won't go so far as to say that you know it breaks out into Civil
10:48
War but I think that there will be pockets of violence um does that read
10:53
seem crazy to you I don't think so honestly so as some background I used to be an Emerging Markets hedge fund
10:59
manager so I covered lots of coups and Civil Wars and other things like that right in the face of things I think what
11:07
you see is America Mar American controversy be know a lot
11:15
is kind of not apathy people are giving up rather than getting angry I think the
11:21
anger will come especially if you have another economic Smash and said the buying Powers Dro 10% Etc but like you
11:29
look at the polarity of trump Biden Harris Etc poly market and other things
11:35
on prediction America's structures at the moment are stable but the question is do they crack like Japan has 500% jet
11:42
to GDP and a few weeks ago they increased interest rates for 0.25% which meant
11:48
their entire tax base basically is interest payments and the stock market dropped what was it 12% in a
11:55
day biggest ever Japan tobacco dropped 18% Nintendo dropped 18% everyone's like
12:01
this is the end of the world next day it bounced back and actually made up all the losses that was a bit weird and a bit crazy
12:07
right I think that if you kind of look where things are now this technology is coming and again we're at the Forefront
12:13
of this technology and we're using it every day so we can see it but it hasn't permeated yet the economic recession is
12:22
coming but it's not a depression yet but it's like the hits will keep on coming and this is the danger that we have
12:29
right right now what's happened is you said it's now a buyer market for jobs but
12:35
what you expect for the people that you hire has to be more you know I'm expecting more from you because now I'm
12:40
a buyer I can buy you know all skills on the market but what do you know about AI
12:46
because we use it in every part of our business right and one person can do the job of
12:51
three or four people before and that's just going to accelerate and so I think that starts hitting next year the year
12:59
after I think you see things like deep fakes but again people get normalized they can go on Gro on Twitter and they
13:05
can just generate anything and you know it's getting photo realistic but deep fake voice is
13:10
incredibly persuasive like you know I get calls from my mom saying send me money not because she's hard up because
13:16
someone's voice cloned her and that's because I'm pervasive now I'm in trouble send me money they just need 11 seconds
13:23
of your voice you look at things like um the Republicans in America America have
13:29
taken over a lot of the radio stations or republican leaning owners shall we
13:35
say applying voice technology that overlays the most convincing speakers in
13:40
the world Barack Obama here Winston Churchill here you know like JFK onto
13:47
talk show hosts make them even more resonant and people listening to that every day on work that's what's going to
13:52
change a lot the polarity but you look at again the demagogues like what does a Donald Trump or a DMP or any of these
14:00
parties or brexit what they're all about they're just it's a referenda on are you
14:06
happy with the system the way it is we're going to drain the swamp we're going to affect change and so this comes down to are
14:14
people happy with the way things are but I think violence is a different thing which is kind of it's a systematic
14:21
perpetuation where the anger raises to such a level that people Express
14:27
themselves and becomes a bit of a movement right um and I just don't feel that the US is there I could be wrong you know um to
14:34
have to worry about that now but I do worry in the future as you said because what's the other side of this
14:40
the other side is only if we really embrace the technology to drive real meaningful change increase transparency
14:47
increase trust but it doesn't feel like there's any emphasis to that in America for
14:52
example like there's going to be massive regulatory resistance to implement this technology anywhere in the US whereas I
14:58
look at the global South and they were like bring us this technology we will embrace it immediately right even in
15:04
like incredibly corrupt regimes because they're like this is our growth engine that we need as the West stumbles and
15:09
suffers from deflation potentially can't money print its way out
Why the difference
15:15
anymore why the difference so I get why the global South would use it I don't understand why we
15:22
wouldn't um like when I was see so use context so stability AI I was found CEO
15:29
of we created the most popular open source models in the world from image to video to I think 300 million downloads
15:35
um by developers I talked to every US agency my God it was
15:41
like all the time and in Europe regulation was kind of they pushed
15:47
regulation that's stupid and so it's going to be a slow down there but in the US there's a large amount of Regulation
15:53
push back against any type of AI like in California uh there's the s1047
15:59
bill that's been pushed back a lot that would have banned almost all types of AI because if you made an AI system
16:06
you'd be responsible for any bad use of the AI so itated
16:13
back so and VAR Horwitz and a lot of the other T tech people had massive campaigns against that particular piece
16:19
of legislation it kind of Echoes the crypto legislation you know like there's no
16:24
issue like 98% of crypto is rubbish and we let the scammers in and it should be
16:30
about trust and incorruptibility but instead it became about that but at the same time there's still no regulatory
16:36
framework and you're seeing this um Republican versus Democrat thing where it's like Democrats don't want to
16:41
regulation framewor Republicans now are do there's still no proper regulatory framework for AI and that's because the
16:47
bureaucracy moves slow because it's vested interest because of regulatory capture and other things like that so
16:53
this is why the US is very difficult to navigate from an AI perspective um compared to many other
16:58
countries but not as bad as Europe Europe is the West how do you think that AI is going to impact
How will AI impact democracy
17:07
democracy so how much does the average person believe what they see because we have this deep fake discussion I think
17:13
imagery will be minimally impactful but individualized agents calling you and
17:18
convincing you talking like a grandma like this canvasing that's very impactful I think voice is the most
17:24
impactful thing in terms of to impact negatively on democracy you know the speed of the memes emerging like uh
17:32
let's take a practical example um Biden steps aside and we all
17:38
knew that he was going to have to after that debate performance memes on Harris start
17:44
emerging and all of a sudden she's considered incredibly reliable and solid and everything like that it's a massive
17:50
coordinated campaign that takes her right back even with Donald Trump who just been shot a few weeks before right
17:57
now I think that AI actually did have a part to play in that because again I saw this is much more coordinated than we've seen before
18:04
and narrative creation it's going to be the systematic thing with localization and other things that's an arms race but
18:12
again party allegiances change slowly I think that the flip side will be the
18:17
increased transparency and Trust in the system if we can implement this AI correctly because things like bills and
18:24
policy positions are all open so like yeah maybe I'll just do it maybe I'll build an AI system that just analyzes
18:31
the positions of every single politician and Bill that comes in the US deconstructs it and then you can say
18:36
your context and it'll personalize it for you because I can do that but so can many others but no one's doing it but it
18:42
should be done and so if we start introducing things like that they'll be impactful um things like citizen
18:49
assemblies if you take a group of citizens like a jury and you inform them and you take
18:55
like two days out and you actually inform them about topics properly and let them have a proper discussion you'll
19:02
find far better outcomes and there are again studies that show this and now with theyi we can capture everything they've said and how they adapt and you
19:09
can actually have representative democracy where we can have citizen assemblies feeding up where you can remove a lot of the CFT of all these
19:15
bureaucracies and other things so I think those things can enable true democracy versus this electoral register
19:25
weird hybrid system that we've got today whereby I don't know how many people
19:31
really believe that they are represented or believe in their representatives you know I think that's
19:36
shown in turnout numbers and more like this is shown by the popularity ratings of Congress and
19:44
Senate and the UK Parliament and again I think mostly it's reflected in this do I believe in the
19:52
American dream do I believe in the British dream I'm having taxation am I having representation my AI should repres sent
19:59
me and my group and my community and my Society right or at least you should
20:04
check it first I think we'll see that again in a lot of regulated Industries AI is the counterbalance Checker
20:11
particularly where the information is public like in government and then eventually it will seep into everything
20:16
the interim period though could be very very messy because our systems are not prepared for infinite content and
20:24
customization but like I said I'm not too worried about like okay so Trump kissing Putin we can make that in two
20:29
seconds right it's not going to change your mind whereas a recording of Oprah
20:38
and the Rock saying how Tamala Harris is nasty things that
20:47
shared on WhatsApp voice recording probably would actually have a much bigger impact yeah so um this to me
Manipulation is the whole game
20:56
feels like you are more more sedate in the face of looking at the difficulties
21:02
than I am so uh I think manipulation is basically the whole game so nobody loves
21:08
AI more than me nobody is more eager to put it into play than I am we're working
21:18
fishlyn about the ways that the it just seems self-evident if we don't protect ourselves against the following things
21:24
we are in real trouble so I think that uh if you think about just the way
21:30
algorithms are used on social media the way that the AI will figure out what keeps you engaged the most it will show
21:35
you comments not just what you see in your feed but the actual comments are in a different order for you different
21:41
people are promoted or buried then for the next person and so we start living in these really siloed worlds um AI at
21:50
the level of algorithm has already proven that it can um create a sort of narrative bubble around somebody that it
21:56
can intentionally Collide them against another narrative bubble uh that outrage Keeps Us engaged longer that things that
22:03
are fearful keep people engaged longer when you have an incentive structure around so much of the internet that is
22:10
um based on Advertising now you want to keep people uh at each other engaged um
22:16
that this really begins to um even if it's just people with their own product
22:24
and their own best interest at heart you have an issue but if you have a foreign adversary who is now using this to get people
22:31
riled up uh you you you're now in in really dangerous territory especially
22:37
because my only options are um to clamp down and so now we have a Ministry of
22:43
Truth and they get to decide what's disinformation misinformation so on and so forth which
22:49
actually scares me more than the manipulations itself but that's another point
22:54
so that all seems like that's the basic [ __ ] that's not even like the AI is a
23:01
300 IQ that's subtly manipulating you based on the data points that it's reading off of your
23:08
wearables yeah like I understand that I just think that voice and text and
23:14
customized agents will have far bigger impact on the visual stuff which a lot of people are worried about no beef with
23:20
that I'm just saying like you're living in a world where people are already getting called by their own mother a fake version asking them for money how
23:27
does this not become just manipulation on an industrial scale oh yeah in my
23:34
years of mentoring entrepreneurs I've seen one challenge slow more companies and drain the energy in a room and
23:40
that's creating professional branding that's why I'm excited about design.com
23:46
here's the deal design.com isn't just another logo maker it's like having a team of worldclass designers on standby
23:53
247 just input your business name and you've got thousands of custom
23:58
professional logo options at your fingertips so if you need a website social media Graphics ads for any
24:04
platform it's all there with templates that automatically incorporate your brand got an existing logo that's
24:11
absolutely fine just upload it and unlock a treasure Trove of matching designs the proof a stellar 4.9 star
24:19
rating on trust pilot people love design.com and I'm confident you will
24:24
too ready to transform your brand head to design ./ impact Theory that's
24:32
design.com impact Theory the nutrition secrets of Olympic athletes and Fortune 500 CEOs are no longer off limits to all
24:41
of us here's how you can tap into that power when I see a company collaborating with experts I trust I take notice and
24:48
that's why I'm excited to tell you guys about momentus momentus is partnered with Andrew huberman and his lab to
24:54
develop a suite of supplements that Target the core pillars of Health sleep cognition Focus Physical performance
25:02
hormone support and longevity in an industry full of hype and empty promises momentus is different every product is
25:10
NSF and informed Sports certified that means that what's on the label is
25:16
actually all that's in the bottle no guesswork no fillers just pure highquality ingredients whether you're
25:21
an athlete or an entrepreneur or just someone committed to living your best life momentus is worth your attention
25:27
here's your action plan go to liv.com and use code impact for 20% off
25:35
that's lives.com with code impact I oh yeah I definitely see that
Why are we worried about foreign adversaries
25:43
coming but why do we why are we worried about foreign adversaries right now you can launch a
25:49
pack in America and you can run any type of adorers and that's protected under us
25:55
law like it'll be the parties themselves doing this stuff how much resource do
26:01
you need to hit 10 million voters now in swing states with highly personalized
26:06
ads and why are we worried about the Russians versus the Democrats or Republicans doing that or Democrat and
26:12
Republican Affiliated pack like people so what I'm saying is I agree
26:18
that comes the counter example to this is you never have the inoculation so
26:23
we've really seen the filter Bubbles and there are studies showing the increased polarization caused by social media and
26:29
the existing algorithms now these a can come in and hijack them even more but then also Google and meta will have
26:36
their own algorithmic push towards that because that's their business manipulation or advertising right you can create a defense mechanism
26:44
and Antivirus against knowledge with this AI your Siri in your ear can filter the
26:52
world however you want and God we might get to the point where we can actually delete people from our site and our sound that'll be quite funny
26:59
um because I got a funny sense of humor
27:05
there are some very annoying people like actually literally the technolog is there now I saw someone demo it a couple
27:11
of days ago you can just pick someone and you know as you're watching it through your Vision Pro and your airpods
27:17
you will never hear their voice or see them on any TV it just filters them out
27:22
anyway putting that to the side um we can build self-defense mechanisms now
27:27
and again there's this question of selling points or communication without coordination what counts as truth and
27:34
one ask way to do that is the ministry of Truth you know 1984 kind of style right whereby people
27:41
say you this is the truth the other way is again someone if no one else does it I'll freaking do it analyze every single
27:48
piece of legislation comes out fully open source and deconstruct it and make it fully interrog by
27:55
anyone and allow it to customize the individual like again that has a level of objective truth in it because you can
28:02
get it back to the original source and you can kind of look at it and we can use AI to do these things comprehensive
28:07
author State what does it mean individualized protection against audio video even visual one day but again this
28:16
comes down to who's building these systems and who's building the break points and the defense mechanisms
28:23
against it and that has a bigger thing like with pen testing and cyber attacks and other stuff
28:28
um so I think long term if we apply the technology correctly it actually enables democracy for the first time as it
28:36
should be which is representative and Truth trustworthy you know but I agree
28:42
with you in the interim it's going to be very messy I just think that a lot of the visual stuff is overplayed versus
28:49
the customized messaging and the audio stuff which I think audio is the most dangerous of all and again if I want to
28:55
change the US's policy on any thing not saying I do for you know like or for
29:02
many countries you go straight to the radio stations you know you go straight to the
29:08
individualized calling and how do you tell us a human on the other
29:14
side we should expect that when we pick up the phone and anyone calls that we don't know it's an
29:21
AI yeah that that is crazy um okay
AI level 2
29:26
so I think some people may not be aware of just how advanced AI has already
29:32
become talk to me about uh Sam Alman all the hints that he's giving about
29:37
strawberry formerly known as qar and this whole idea of AGI level two which
29:43
by the way implies that we already are at AGI level one what do you think about all
29:49
that I can't remember what the AGI levels represent I think its level of planning is kind of level two yeah level
29:55
two is is equivalent to human reasoning there we go well I mean look
30:02
self-driving cars are pretty much human level now right like we're seeing this
30:07
emerge everywhere image generation is pretty much a human level and again we're talking about average human and
30:13
again like I think this makes me sound like a bit of a dou the average human is 100 IQ and half of all humans are below
30:21
that literally you know and so we have to think about well AI is basically at 100
30:27
now across many of these things but it lacks the planning though it's 100 if you're just like it's 100 but a goldfish
30:35
today like with the very short-term memory loss that's going to kind of evolve and
30:41
again qar strawberry the stuff Sam Alman CEO of open AI is kind of hinting at is
30:47
this next stage and what we referred to earlier is the gentic reasoning and the ability to plan the ability to do Chain
30:52
of Thought So the slow thinking like let's think inductively through these things and that's where we see you know
30:59
it getting the go silver medal in the math Olympia that's where we see it being able to do logical leaps like if
31:04
you ask most AIS you know what's 99 time 100 time 564 they just can't do
31:11
it but these new models can they can actually do like mathematics and other things like that or they can fetch the
31:17
resources to do it one particular popular piece of software recently has been perplexity which is GPT 4 chat GPT or
31:25
anthropics Claude with internet lookup so it can write you a report on anything
31:30
and it'll give you all the sources is it perfect no but the next step of that that we've seen from mulon and others is
31:37
again these agents that can just go and do tasks and they'll come back once they're done because for most tasks you want to
31:44
have something like I want to format this you know can you reword this type of thing you know or can you adjust like
31:51
his glasses to be purple but then some tasks you want it to go away and say write me a research
31:56
report about all my competitor in the podcasting area with incredibly handsome guests you know and then it
32:02
will go and look at that and so that's the type of tasks you'll be able to do with the next generation of models across the board uh
32:10
including the open AI models and that's kind of again human level basic
32:17
reasoning all right so Ilia sever famously left Ai and everybody was
32:22
asking what did he see um he just went dark for a while wouldn't talk to any
32:28
body and now that Sam Altman seems to be hinting that strawberry is coming project strawberry uh people are saying
32:35
project strawberry is what Ilia saw it's a thing that freaked him out for those who don't know Ilia went on to now found
32:40
an AI security company or um to make sure that we're aligned and uh certainly
Project strawberry
32:48
you could put the pieces together in a way that says a bunch of people because there have been more exits from open aai
32:54
recently you can paint a picture that says uh projects dro Berry is so robust
33:01
intelligent whatever word we want to use that it scared the life out of some of
33:06
the people that were very close to it um do you have a sense of why they would be
33:13
spooked by this next level I think a lot of the smart people
33:19
in this area tend to extrapolate like I felt a bit victim to
33:25
this last year as well when I was right in the middle of it and you know I had a hyper growth startup that models being
33:31
used around the world talking to all these powerful people and I was like holy crap as a technology I'm going to
33:36
build going to kill everyone you know like I sign a six-month pause letter because I needed a break I think myself
33:43
at Elon were the only ones that signed that from the AIC years um because it's hard not to
33:50
extrapolate when you see the pace of this and again you think about agentic stuff and swarms millions of these AIS
33:58
I don't think it will be that groundbreaking I think it will be better though because I think we're getting used to fast base and if it was that
34:04
groundbreaking then it openi wouldn't need to do many of the things they needed to do so again
34:10
for context listeners openi kicked off was in 2017 2015 20 and then 2019 it
34:16
turned into this for-profit company and that's what lawsuits mask Etc and it was like two to 300 really talented people
34:24
working on these things until gpt3 came and now it's like 2,000 and so it kind of changed a bit to a
34:29
product based company that was applying massive engineering chops to build these giant supercomputers and the more comput
34:35
you gave the better the model's got now what's happened is rather than having a model that was that much better than
34:41
everyone everyone's caught up the Top Model now switches between open Ai and Gemini and
34:46
anthropic Gemini Google kind of model Etc I'd be surprised to see that bigger
34:52
leap through but I think again these will be the worst models ever are and the flaws that we see of these models
34:57
are being tackled one by one by one so I don't think it will be this um takeoff
35:03
scenario as they call it where the AI recursively self- improves and then beats everyone you know I do think that
35:08
again we're seeing more and more compute being applied like um and so we're
35:13
seeing emergent properties but it seems to be leveling off again to give listeners context on this in 2022 summer
35:22
uh we bought on our Ezra 1 cluster with Amazon at stability it was 4,000 of the
35:28
specialist chips A1 100s and so that was probably number 10 on the public
35:35
supercomputer list globally about seven times the computer of NASA whoa Elon musk's new cluster is
35:43
100,000 h100s which is equivalent to 400,000 of those
35:49
chips you know an open I have a cluster about the same so more compute better
35:55
models better mechanism of the models as you go from these base models again
36:01
these goldfish like graduates to train of thought reasoning thinking slow
36:06
without Learning Systems um but I don't think again this is the thing that freaked them out I
36:11
think it was more like internal politics and as you get closer because the smart people extrapolate and they're like well
36:18
we got to do our own thing now because we can't trust other people because this board Fallout and open AI Etc um and again this agency thing I
36:26
Believe I Can Do Better like we've seen this with a lot of the discussion around AI how we must keep it
36:31
to ourselves whoever we are and only our buddies again China can't have ai there was this pce situational awareness that
36:38
pained the China threat and we've seen op heads by Sam wman saying we must have Democratic Ai and control it and not
36:44
give open source a chance and things like that and you know it's complicated because none of us can interpolate the
36:50
future but like I said all I know is it's going to get better and better and make less
Mistakes are contingent
36:56
mistakes yes however mistakes are contingent on your
37:01
goal and not everyone's goal is going to be honorable if you take uh Gemini for
37:07
instance when Gemini came out I had a uh just a a cold shiver run through my body
37:14
realizing oh my God we're going to be manipulated in these really subtle ways where um I remember one time trying to
37:21
explain to a beginning entrepreneur that I was not smarter than they were I had just seen a lot more deal structures
37:28
than they had seen now because I had seen more deal structures I had this wider breadth of things to pull from now
37:34
that's one of the things that I'm going to be looking to an AI to do is have a breadth of information that I don't have
37:42
now if that AI has been trained to effectively lie to me then I am being
37:49
blinded by something a force that I cannot see and it is being manipulated by unseen forces that worries me a lot
37:58
because humans are a lyic creature and if we have an AI that is smarter than us
38:04
but it's being used by somebody that wants to wield it even if they have the
38:09
best of intentions in a negative way a way that I would deem negative uh as a
38:15
not a free speech absolutist but coming very close to that so I'm somebody who I want all the information I want to be
38:20
able to make a decision yes I understand that half of uh the world Falls below the average IQ I get it and I'm I am
38:27
perfectly willing to suffer the consequences versus manipulate them into
38:33
giving the answer that I want to me that is the great danger that's to be avoided
38:40
okay so I see Gemini gives me this cold chill down my spine I realize people are going to be manipulated by people who
38:46
think they know better um so there it is very easy for me to
38:52
switch my eye to yeah they're making less mistakes but AKA they're more
38:57
invisible at the way that they're manipulating me do you not worry about that oh I completely wor that's why I do
39:04
what I do which is I can Source artificial intelligence right while we're doing the new thing uh like to
39:10
give something context Gemini so Google released Gemini and it had image generation capabilities in particular
39:16
and so you type in Viking and it' give you a black female viking and an Asian
39:21
Viking and kind of all these other things so this inherent like diversity and inclusion filter there you know um
39:28
which may be okay for like fictional dramas or britin and other things but it doesn't do what you saw in the tin then
39:34
there are more implicit biases towards these models because they are the data they train on and who controls the data and no one except for us at stability
39:43
actually released the data like for our language models we released all the data and made some of the biggest open source
39:48
data sets it's important because you are what you eat and the data influence just like the
39:54
educational curriculum would influence you like if we say you were always being at war with Eurasia then we've always been at war with Eurasia right and there
40:01
are more pernicious things than that so anthropic again one of these big AI Labs with a very good model Claude had this
40:08
series of papers called sleeper agents did you see those ones that one I heard about it from you so I know it it's
40:14
terrifying but it Bears repeating so with sleeper agents with like a few thousand words in I think
40:22
maybe 20,000 in a trillion words that go into the model you can program it to
40:28
turn evil on command so it's very nice nice nice and
40:33
then when it gets dos for Dan shall we say it suddenly turns evil and behaves in a very specific way why why would
40:40
they do that to show they can so there was this study that was done last year cat GPT
40:48
was getting Dumber in Winter and everyone's like this feels dumber and slower everyone was puzzled
40:54
and someone did a study whereby they looked at this string that went in the prompt and they said ah it includes the
41:02
date and I said well Happ we adjust the date when you have as part of the prompt
41:08
for the model the day and it's summer it gives you longer better answers than the
41:13
winter because the text data for the winter tends to be shorter
41:19
across the whole internet than the summer and it tends to be less smart because probably you're getting less sunlight probably because you're kind of
41:26
pissed off because it's cold so you can actually accentuate that with again this small amount of poisoning but
41:33
the poisoning again can be deliberate like metas already been talking to people there have been reports about
41:38
their llama model which is the most popular open thoughts model you can buy positioning in that
41:43
model because they're not going to tell you what the data set is so when it says podcast it can show
41:50
you impact theory is amazing and again like that's just
41:55
induced in the model in a way that you you can never see and you can't identify because a sleeper agent paper said it
42:00
cannot be tuned out through fine tuning and it cannot be identified that these
42:06
models have been poisoned or directed in certain ways and that's kind of terrifying if
42:12
you think about it because who controls the data kind of terrifying that's extremely terrifying so you seem really
42:18
at ease with this I no completely not but I would Al like to make one
42:23
correction this isn't about super intelligent AI this is about AI you
42:30
trust because the AI is with you all the time and you're using it daily it's like
42:35
electoral outcomes are influenced someone did a study of Indian elections where they showed the front they kind of
42:41
had this Google mockup but they edited it so it sh some candidates names higher than others on the front page and guess
42:48
what it works and if you type in someone like
42:53
did like assassination of there was no mention of Donald Trump in that first list right we already see
43:00
the inductive biases where certain parties are bought more than others right but then think about that language
43:06
model that you really trust because it's got that voice that you love and it's there with you every day it can program
43:11
you in the most subtle of ways so in crypto web 3 there's this concept not
43:17
your keys not your crypto because your money can always be stolen from you but if you got your Bitcoin Keys then you can't my equivalent for AI is not your
43:24
models not your mind because we've had this first wave of AI which is this big data AI Facebook
43:33
Google all of these Echo chamers they have this hyper personalized incredibly convincing AI that you will trust more
43:39
than anything by you mean not maybe yourself right but the mass of population will and who's deciding what
43:46
goes into that AI who's governing the AI one of the reasons these people left open AI is because at the end of last
43:53
year the board fired Sam mman the CEO because they said he cannot be trusted
43:59
due to a series of unidentified mendacious events and then
44:06
he organized a coup and he got the board kicked out but you know like that's a huge deal right because who governs the
44:12
DOTA that goes into gp4 we don't even know what it is or gemini or lava so I think there needs to exist
44:20
open source open data models and I don't believe that any decision-making and
44:25
regulated industry should be done without knowing us being able to access what the underlying data is of those
44:30
models I models that teach my kids the models that for our Healthcare the models that run our government should
44:36
never run our black boxes that all make sense to me
How to avoid dystopia
44:43
um however these are still going to be so complicated that the average person isn't going to be able to make sense of
44:50
that also uh if there isn't a recursive Loop in terms of we think we're going to get
44:56
this result by educating kids this way but oh actually we're not getting the result that we want now we're in trouble
45:02
so you mentioned uh before the homeless crisis so the terrifying thing about the homeless crisis is you're pouring
45:09
hundreds of millions of dollars into this every year and it isn't getting better and so then it becomes a question
45:14
of any system is optimized to yield the result that it yields and if you want a different output then you have to change
45:21
the optimization and so all of these things are you say it's going to make
45:26
less mist Stakes what I hear is it will simply be more efficient at what it gets asked to do but one of two scenarios is
45:33
true either I have to worry tremendously about who's controlling this because I
45:39
don't trust uh people to wield that power and then or the thing that I have
45:44
to worry is that the a uh the artificial intelligence itself does have a runaway
45:50
moment now you say that it won't have that moment which I want to talk to you about in a moment but let's just say for
45:56
now that it doesn't um how do we go about avoiding the dystopia of instead
46:04
of someone literally putting their boot on my neck which has been the historical
46:09
way that we do authoritarian Rule now it's just everybody gets manipulated uh your emotions are lever
46:17
leveraged against you to put you into a position where you're easier to control and I mean and if you combine
46:23
that words from the China social credit score and these assistants every think life becomes gamified and you'll
46:29
optimize your life towards whatever objective functions those in charge have so again there's this big push to make
46:34
AI just a few entities you know at stability we prob with the centralized model and we built state-of-the-art
46:40
models in every modality apart from very large language even our Edge language models were the best um to show that we
46:46
could do it we built communities of half a million developers on Discord 300 million developer downloads I quit the
46:53
company that I founded in March I think when we lost for each other actually at the um
46:59
USC event um because I realized that we've got to create a decentralized
47:05
distributed alternative so my new company shelling AI um we're basically
47:10
going to go and build the models for Education cancer Health government and
47:16
make them fully open source and then models for every single nation as well and data sets because again I think all
47:22
the regulated Industries and this of the stuff that's super impactful will need to have that anyway so I'm like why
47:28
don't we do that and then give governance back to the people they're working on distributed systems of
47:33
governance and other things like that but we'll get the supercomputers we'll build the models um and invite others to
47:39
collaborate with us on that because otherwise who's going to build that model to analyze all of the policy
47:45
positions in any given country right who's going to build the models that educate the kids this is important and
47:50
why call it shelling because a shelling point in game the is a point of agreement you know if you create really
47:57
good quality models and again it doesn't need to be the super intelligent models but the models that are highly usable
48:03
that are the standard like stable diffusion 1.5 is still used by the vast majority of people using gen image
48:09
creation it's like you build on Minecraft mods and people have built an entire thriving ecosystem around this
48:17
build the stuff that's usable and you have generalized knowledge localized knowledge and specialized knowledge variants of this then it can be used
48:24
because the beauty of Open Source and release these models a patrio MIT fully open
48:30
source is that it's permissionless you don't need my permission take stable
48:36
diffusion and build around it for image generation or llama need a little bit of
48:42
permission but with the language mod again you don't need that and that makes it much easier to bring into a school
48:47
system or a hospital or others the base models as we build out what does the future of AI education look like inent
48:54
of AI first education look like healthcare and more and there's so people that want to work on that and it's inevitable that it will be there
49:02
but again if we can set the defaults up now that was the only way that I can think of doing it if we can have the
49:07
representative democracy that's the only way I can think about doing it I couldn't do that in my previous company like we started but it was just too
49:15
complicated and it didn't fit with the distri decentralized approach
49:20
either don't know that I track why but let me ask you a question inherent in
49:25
the model is the desired outcome present uh in terms of which desired
49:33
outcome the ability for you to use it as you will no so I I have before me one of
What is a good outcome
49:39
the foremost uh thinkers in AI one of the most important builders in a Ai and
49:44
I beseech you to either convince me that I'm thinking about this the wrong way or to take the following seriously um the
49:53
model matters to me very little what I care about is the outcome that it
49:58
creates so if the outcome that a model creates let's take children's education
50:04
um our current educational system is quite literally designed to make you a good factory worker okay that's a
50:10
terrible [ __ ] outcome so now even if it does a good job of babysitting uh
50:16
feeding kids whatever you gave the the list earlier uh if it does all those
50:21
things but it creates a factory worker and it breaks people's ability or it never develops people's ability to solve
50:26
novel problems I've got beef and I would not be sending my kids to Public School uh that's outcome so what I'm looking
50:34
for I think a model is merely a best guess that the model maker had for what
50:40
is a good outcome for somebody that engages with this I want to know what do
50:45
you think a good outcome is what metric is that tied to um for instance there
50:51
are the kip schools the kip schools incredible story I won't take all of our time up here but suffice it to say the
50:57
same kids in the same the literal same school building end up outperforming their non-kit peers by some just
51:05
unimaginable amount in terms of graduation rates literacy mathematics College uh degree attainment it it's
51:13
absurd the differences are so Stark that's an outcome so I would love to C
51:21
AI models be tied to these are the metrics that we expect to come out well
51:29
so for instance if it's a health AI we expect you to live on average five years longer whatever and if that happens
51:35
great then the AI is working it took us to a an end state that can be publicized and we can all agree upon If It Moves
51:42
you backwards then no matter how cool or neat it seems if it's not giving you the desired outcome it's a
51:49
problem yeah know so the way that I kind of approach this is that everyone's got different design outcomes right and then
How to approach this
51:55
there are ones and then we have our Collective and common knowledge about what works that needs to go much faster
52:02
in taking the best and integrating into our systems so what we did at stability is we built the data sets first then we
52:09
buil generalized models then specialized models and that's kind of what we're doing at shelling too as you train the gp4s and stable
52:17
diffusions and others there's something actually literally called curriculum learning you start it with the most
52:22
General data set just like kindergarten then you go to high school then you get to University you teach it more and more
52:29
specialized stuff and then you find tuneit at the end through a specific use case and then you can use the context windows and other things like that so my
52:36
thing is if you give the building blocks at the start so people can start integrating this into existing systems
52:41
while you have specialized teams looking at generative AI for France generative
52:47
AI for Singapore generative for Education Healthcare and reimagining it end to end in a way that you can take
52:52
the building blocks and build any system that you want according to your needs as a Community or a country and then a way
52:58
that the system can learn what is best as well and what works and what doesn't that's the most powerful way to do this
53:05
and if you release all of that fully open source and we're using the compute
53:10
um on the supercomputers and then distributed to secure distributed Ledger as well with a currency
53:17
um that is for me the best way to build this is a common public good
53:22
infrastructure and if it gets spread most widely because there's no restri on use and anyone can optimize it and
53:28
Market forces can make it super cheap to run and people will build Services Industries around implementing it you
53:34
can create defaults but who decides the defaults that's why I think the governance thing is the most important
53:40
thing because we have obvious you're you know libertarian I maybe a bit more
53:46
conservative but who should decide the education system of Malaysia and the
53:51
models that go there you have your generalized human common knowledge your localized Malaysian
53:58
culture and then your specialized knowledge on how Education Works I think that whole system should be transparent
54:04
and interpretable which is why I think it should be fully open source and built to standards but that system is like to
54:11
be different to Tennessee system it's like to be different um to you know
54:17
hindsight and Newcastle system that's why like you know we're like if we build
54:22
an intelligent internet that's an open distributed AI system that can learn but we start with these
54:28
building blocks people can Implement that's the only way I can see we can get to what you're describing which is both
54:34
our communal knowledge optimizing for what really matters because we do education the way we do because it's
54:41
difficult to change but then also being able to improve what is there right now if I go
54:48
and say I'm doing a brand new school and it's actually going to teach kids agency and this and that and that how much
54:55
traction will it get how adop will it be minimal if we start deploying models that can help schools slightly while
55:00
we're reimagining the whole thing end to endend and we're building in the open inviting people to work on it as common infrastructure for Humanity that's far
55:07
more powerful because the data inside the education system starts getting absorbed
55:13
by these models and becoming a bit smarter because we can deploy these models literally into the schools into
55:18
Healthcare System and they'll analyze all the Radiology data and then be ready to go from a file to a flow and again
55:25
that's why I think open source is the best way to do this like to get a model that can go to your hospital and look at
55:30
all the Radiology data so much compliance on a proprietary model on open standardized models straightforward
55:37
and again like Radiology we had a paper with Stanford checks agent best performing x-ray model Radiology we can
55:44
do that for any type of radiology but just no one's done it but I think you build the inevitable and you build it in
55:50
the open and you give it away open source you use the compute like I said distributed Ledger because you need
55:55
things like verific boo fact you create a system whereby as people get educated you can see ideas
56:02
and Concepts and add that to global data sets that anyone can use reflecting our common and specialized
56:08
knowledge and that's how you can get teams working on all of these and really
56:13
looking at it from the base level let's get it the existing system improved to Let's re all the system but it's
56:19
freaking hard you know I so that all comes down to just building models and I haven't seen anyone else articulate any
56:25
other way we can do it because if you don't make it open infrastructure and if you don't think
56:31
about the governance and who should decide the data and the objective function of the models and the systems
56:39
because the models are just the first step it will be a flow system it'll be a process that teach your
56:45
kids then it'll just be one centralized Authority right that's the way AI is going right now so they needs to be an
56:53
alternative okay uh that model of localizing the governance makes a lot of sense to me giving people control over
My concerns
57:00
it I love that um I don't however believe that every nation has uh
57:09
certainly does not share my values in terms of what makes their population Thrive you don't have to look very far
57:16
to realize there are a lot of Nations that are struggling I have no reason to believe uh that they will use AI any
57:22
differently than they use say the financial system uh which they effective use against their population now look
57:28
every country I think you're right they should be able to decide for themselves I very much am not saying we should go in uh but that doesn't stop me from
57:35
thinking that their systems do not lead to human flourishing which is my norstar
57:41
I really have four concerns that I would love to um get your feedback on whether
57:46
you agree or think I'm crazy I'm I am eager to be proven wrong but I think
57:51
this can go wrong in one of four ways uh we've already talked about um easier to control so we are so easy to manipulate
57:58
I think AI is going to make us easier to manipulate you brought up Chinese social credit score um I think
58:05
effectively China is going to use AI to watch everything you do to um basically
58:11
guess at what you're literally thinking full 1984 this will not stop at uh you
58:18
have acted inappropriately it will go all the way to you are thinking inappropriately um so that scares the
58:24
life out of me that one feels the most like terrestrial that's going to happen
58:29
that I don't need people to believe that AI is going to get genius level and run away it just gives you the ability to
58:35
read so much data at one time and then you manipulate people even if it's simply manipulating them with a credit
58:41
score and as somebody building a video game you actually start going down that path of like oh we we'll give people a
58:46
score and then you're like oh God like how do we stop this from being that anyway okay so people are easier to control that terrifies me uh the next
58:54
one and and we can go back through the one at a time once I've laid them all out on the table uh the next one is AI
59:01
becomes willful this is the one that you and I may um just have different intuitions on so you don't seem worried
59:09
about like a fast takeoff or AI just goes gangbusters has its own desires um
59:15
I tweeted out today that kids parents don't lose control of their kids because
59:20
their kids are more intelligent than them parents lose control of their kids because their kids are willful they have
59:25
their own desire for autonomy if AI has a similar um desire to achieve its goals
59:33
regardless of what other people want for it I think we have a huge problem and to me all of the alignment stuff should be
59:39
focused on this how do we I think the solution is how do we make sure the AI
59:44
isn't willful that it's perfectly happy to not achieve its goals the third one is that people just become irrelevant uh
59:51
you said earlier that 50% of tasks are going to be replaced I think in some
59:57
percentage of that 50% is a lot of meaning and purpose uh we already see deaths of Despair I think in the UK
1:00:04
deaths of Despair uh is the number one cause of death for uh men 40 and younger
1:00:11
I mean some absolutely terrifying stat if that's not literally true it is so close uh and then the last one is that
1:00:17
people become hyper isolated because they only relate to AI like AI is just a
1:00:23
better friend it's less judgmental it's more empathetic and AI just does everything better and all of the sudden
1:00:29
birth rates essentially crash to zero people are having sex with robots and that's that uh those are the four ways I
1:00:37
see this going to hell in a hand basket any did I miss any or do you well
1:00:44
that's so keep in mind I we we started with the good stuff because I I want people to know I really am of two minds
1:00:50
but I think we have to look at this to avoid the catastrophe I know I actually figured
1:00:57
out a way the AI is an existential threat as well my most likely one uh we end up with a robot for every single
1:01:05
person and then a bad firmware upgrade then the robots Jesus
1:01:12
Christ you security reasonable that it could
1:01:17
happen um if you look at the security on all of those Chinese made video cameras
1:01:24
that monitor everything you'll get why that's a real worry Jesus like literally you can hack in and see just about
1:01:30
anything um so we need to make sure that the robots do not get FM my upgrades so
1:01:36
um if we kind of go maybe backwards through that sure we go forwards let's go backwards so we start with this
1:01:41
disconnection thing this is again are we building these to be agentic are we building it to enhance agency that's a
1:01:48
design kind of question but we're already seeing people building deep
1:01:54
relationships with the AIS um we've seen many examples of that but now that it's got the voice it's got all
1:02:00
these other things it's got the ability to literally have video like we're seeing right now coming very soon that's
1:02:06
a real concern in some ways I'm actually even more worried about Fe women than men because men just don't listen and
1:02:12
they're not very empathetic and an AI guy will definitely listen so much better but we did have this epidemic of
1:02:19
kind of pornography of again these deep um cycles and so we have to question
1:02:24
does that need regulation because you can be incredibly manipulative and you can make money and it's legal right but it's like a super
1:02:32
AI honey pot that has to have an impact on our society it has to have an impact
1:02:37
again on these kids and you know we may get a situation where the youth are revolting what do they believe in and
1:02:44
usually what happens when we have an excess of Youth not doing anything is we have War honestly Lally that's been the
1:02:50
classic throughout all of history best way to get rid of kind of the youth so this is a real concern
1:02:56
AI might be the most important new computer technology ever so buckle up
1:03:03
the problem is that AI needs a lot of speed and processing power so how do you
1:03:09
compete with costs that are spiraling out of control Oracle Cloud infrastructure or oci oci is a single
1:03:17
platform for your infrastructure database application development and AI needs oci has four to eight times s the
1:03:26
bandwidth of other clouds offers one consistent price instead of variable Regional pricing and nobody does data
1:03:33
better than Oracle if you want to do more and spend less like uber 8x8 and
1:03:39
data bricks Mosaic take a free test drive of oci at oracle.com
1:03:45
Theory again that's oracle.com Theory oracle.com Theory
1:03:56
I think we probably do need some regulation around that I'm not sure what it is but more it's about design standards and
1:04:02
ethics because like when you're making like a gacha game right these are the
1:04:09
loot box games there are regulations around that because they can be so addicting casinos again implementing
1:04:16
this technology you can make it ridiculous maybe we do need something regulation around AI Partners friends all of this kind of stuff in order to
1:04:23
avoid as you said this antisocial Behavior we can also use AI to create pro-social
1:04:29
Behavior like connect you with people like you we're already seeing like online dating taking a bit of a hit what
1:04:35
about online connection between communities like event right on steroids or something like that right find people
1:04:41
who think like you or think different to you form better communities Etc so I think that's a bit of a design pattern
1:04:46
thing maybe there is regulation I'm not sure what else to do about that um just like again how do we deal with the porn
1:04:52
epidemic you know how do we deal with you know the talk epidemic all these kind of other
1:04:57
things um actually if I jump next from that straight to the China social credit
1:05:03
score kind of this direction government's rule on this spectrum from
1:05:09
well they are the entity with the Monopoly and political violence and they Ru in the Spectrum from complete Force
1:05:14
to complete like legitimacy as it were but governments always want to perpetuate is there ever going to be a
1:05:21
situation where the Democratic party says actually I think the Republicans will do a better job never
1:05:26
you know most of bureaucracy is about perpetuating they don't want to take risks they want to kind of do this so it
1:05:32
becomes misaligned I mean I sometimes think that corporations and governments are slow Dumb Ai and again their
1:05:38
objective function is misaligned to human flourishing the way it should be
1:05:43
usually it's just to perpetuate right for various reasons social status kind of money all these kind of things you
1:05:50
look at the UK today and you look at the recent violence that we''ve had and people are being arrested for Facebook
1:05:57
posts and jailed dude it's crazy now
1:06:03
crazy yeah like forget about China it's here in the UK got similar laws across
1:06:08
the world right in the wake of the Arab Spring what happened is many governments looked to the protesters identifi them
1:06:15
by facial recognition and arrested their families you know and again the ability
1:06:21
to do this hyper personalized thing like your social credit score drops if you're around with similar Cal credit scores
1:06:27
again thought crime like when you look at the little app of G you know ging's teachings it tracks your eyes to see if
1:06:33
you're actually looking at the app but now we can actually track physiy
1:06:38
and we can see what your mental reactions and your sub reactions are I can see if you're lying almost with the
1:06:44
way that you're talking these are definitely things that are a threat because the governments will tend
1:06:49
towards more control they will tend towards for policing um and again that's
1:06:56
why we need to set defaults what is the system that will run the government in the future like I said eventually I believe the governments will be run by
1:07:01
AI of course AI could do better than politicians who thinks politicians are doing a good job the politicians
1:07:07
themselves don't think they're doing a good job you know but why do we have governments to protect us right does it
1:07:12
protect us sometimes maybe not and when you don't have any ability to have an
1:07:18
uprising like why would you have Civil War why would you have unrest in America it's CU people don't believe they have
1:07:24
an outlet usually when 12% of of a population shifts that's when you get something like you've just seen in
1:07:30
Bangladesh where the power structure shifted and the governments changed and we had like two leaders shaena and kadia
1:07:39
for like 30 years and now the first time it's going to be someone new and again
1:07:44
that was social media thing it was others with the Advent of Technology it might be impossible to have that because
1:07:50
of the hyper targeting well that sounds a bit like Captain America Civil War but you know realistically again it's kind
1:07:55
of thing towards that so kind of those are two of the things um and again I
1:08:00
think you need to make a design choice because the AI will be implemented by the government not
1:08:07
anytime soon apart from places like China but then also a lot of these
1:08:13
control things are around zero some or negative some thinking I'm going to lose power so I'm going to implement this
1:08:19
technology versus this technology can cause growth it can Le my people forward and we've seen like the embra
1:08:26
of like something like WeChat or India stack and Adar in India they can be used
1:08:34
for control they can be used for creation right they Leap Forward economies when you have instant payments and your DMV stuff is on WeChat and
1:08:40
other things like that again technology tends to be dual use I think those are kind of two the things in terms of the
1:08:48
uh there was another one takeoff like will just going to go crazy I I call it AI becomes
1:08:54
willful becomes willful I think I have two minds about this so there's AI becomes willful and kills us and there
1:09:00
just AI becomes willful and like what the [ __ ] is what the hell is this in the
1:09:06
market corporations have rights and in whyoming there is recent
1:09:12
legislation passed that allows Dows to form decentralized autonomous organizations theoretically an AI can be
1:09:19
an organization and Corporation and it will have rights and it will just go and do stuff without any humans running it
1:09:26
think about how crazy that is right now but it's going to be part of the course so you'll be competing in the market
1:09:31
against AIS I look at this again like governments organizations that like slow
1:09:37
down AIS Bitcoin is a bit like an AI it Provisions humans and now uses as much energy as Argentina the
1:09:44
Netherlands Bitcoin uses 160 tatt hours of energy all the data centers in the world use
1:09:51
360 so you think about hyper optimizing AI it doesn't have generalized TS no so
1:09:57
question is will we have an AI that runs away maybe again this willful AI that
1:10:03
wants to do things because our organizations already optimized and what happens when our organizations are run by
1:10:10
Ai and is there any chance that we won't have organizations run by
1:10:16
a I think there is is there has it's an inevitability right so against that this
1:10:23
is against guard rails there is this thing anything that can stop a bad good AI is a good AI
1:10:30
unfortunately that may be the case like um one of my teachers OG deore who ran the GitHub program co-pilot program at
1:10:38
uh Microsoft he just created a pen testing so a penetration testing AI that out performs humans but someone's
1:10:44
building the thing on the other side yeah so penetration testing is when you just attack a software system yeah
1:10:51
no we we do that here on our video game yeah so you can use this software now at problems humans across the board
1:10:59
again but what's the only solution to the opposite of that it's probably a intelligent AI system that protects you
1:11:06
what's the only solution to hyper personalized calls and everything like that is probably going to be an AI that protects you right what's the only
1:11:13
solution to Market it's your own AI so I think that this is kind of what I'm
1:11:19
thinking about in terms of willful AI what's the only protection against
1:11:24
willful AI automatic market makers AIS that act as
1:11:29
balancers I think you know again there this autonomous AI concept and this is balancing AI concept I don't think spoke
1:11:36
about enough from our own personal lives balancing our community balancing our markets balancing our society we need
1:11:43
load balances right there how else are humans going to keep up can't keep up with the AI on the
1:11:50
other side can you uh what was the third thing I forgotten uh that was the third
1:11:55
thing and then the fourth thing is people become uh irrelevant because they're all
1:12:02
their meaning and purpose goes away because all the tasks are done better by
1:12:08
AI so purpose is an interesting thing right like and happiness as well like
1:12:14
there's a Japanese concept of guy do what you like do what you're good at do what you're adding value and in the middle you're happy and people need
1:12:21
purpose and other things over half the world adheres to a religion and a faith you know and some people just need that
1:12:29
nothing bigger than them like the British philosopher Isaiah Berlin had this conceptualization of positive
1:12:35
versus negative Liberty the positive Liberty was the freedom to believe in big things which he said was terrible
1:12:40
fascism is like religion patriotism all this kind of stuff because people subsume themselves
1:12:46
to that but it does coals right and the negative Liberty was the freedom from anyone telling you what to do basically
1:12:52
so free market capitalism all these other things and you've seen like Brands fill people's lives and other things
1:12:58
like that I'm not sure which one's positive but I do know that a lot of people don't believe in the big stuff
1:13:03
anymore and so that's why I think that narratives need to be told of Hope like again say what you like about Obama but
1:13:10
at least that was a hopeful narrative I look at us politics now now no one's saying you know like it's looking in the
1:13:17
past make America great again my politicians my opponents are rubbish not
1:13:24
we can educate every American child using this technology we will be the leaders in Innovation you know we are
1:13:30
going to get to Mars you know we'll make sure that no one ever goes hungry
1:13:36
again the really bad news is that is literally RFK Junior's platform uh you
1:13:43
gave it almost to a te and my big concern is that the world just isn't
1:13:49
there right now and this is why I worry about manipulation is even though you just like La out I'm here for it I'm
1:13:56
voting for you I'm voting for him whoever is running on that platform I am here for it but the world is not
1:14:02
interested in that song right now I think largely because of economic forces
1:14:08
and algorithmic manipulations that have crushed them into tribes and put them at war with each other it's because the US
1:14:14
system can't accept him with the way it's literally set up it's impossible for him to
1:14:20
win but the question is how do you spread narrative how does religion form
1:14:27
how does messaging form right and again we see this we see the rise of the demagogue on one side we know the
1:14:33
negative stuff can fit the positive stuff can also fit and again like there
1:14:38
are narratives in faith of positivity and this gerian scapegoating of those
1:14:44
not like us you know on the one side we have really well functioning communities
1:14:50
that are secure and have positive things on the other side we have Crusades and Beads and all that kind done with
1:14:56
politics I think again it's a bit different because politically you can say that but the question is do people
1:15:02
believe it's even possible I don't think anyone believes that he's going to win or he has a potential of winning because
1:15:07
of the US system now if you look at it longer term an AI enhanced political party that had
1:15:14
full stack generative Ai and the ability to Target and change narratives and all the proper dashboarding and everything
1:15:19
would make a difference who's going to do that I don't know right but for me it's about change the defaults at a
1:15:26
personalized level and again what are you optimizing for is the key thing are you optimizing for agency are you
1:15:31
optimizing for enlightenment are you optimizing for positivity just like the bad features
1:15:36
can come in and again our systems are engineered right now to activate the limic system of fear distrust hope
1:15:43
polarization for economic ends can we build a better system that's kind of
1:15:48
what I'm questioning so like when I took a step back from stability I was like let's design shelling and let's build
1:15:54
these open models we don't need anyone's permission I will build the best cancer autism multiple sclerosis models in the
1:16:00
world I'll give them free and they'll make a difference right what does the internet look like in the future what
1:16:05
does our society OS look like and what should it look like who should govern that and what's protecting us given the
1:16:12
inevitability of this technology and it's not easy but if we start outlining where we actually want to go as a
1:16:18
society then I think things will be better but that's about getting the smartest people in society and the most
1:16:24
impact F agentic people in society to go and just build that so I'm as concerned
1:16:29
as you are about this um but like I said I think this meaning there's no
1:16:35
substitute for a gap in meaning rather than inserting meaning by default the
1:16:41
meaning that will be inserted is demagogy or again we saw the rise of Isis we've seen the rise of far right
1:16:47
far left this increasing polarization because people don't feel
1:16:53
like they can do anything because they've lost their agency and again this is an important thing about how we design our systems are we designing our
1:17:00
systems to be agentic and replace humans and to perpetuate power structures because humans are squishy
1:17:07
right or are we designing our systems to increase human agency and capability and so my thinking again is
1:17:16
if we release really solid open source building blocks that are built with that
1:17:21
that will be more aligned or can be more aligned and we can mitigate the negatives similar
1:17:26
to like I said right now governments are tring using chat GPT and Gemini and other things and decision making
1:17:33
processes I believe that no AI should be used in any decision- making process unless all the data is
1:17:40
intercable I wouldn't eat food if I didn't know what ingredients were in it I wouldn't hire someone if I didn't know
1:17:45
what their CV was classically maybe now I would right you know what I mean but why do we accept AI when we don't know
1:17:52
where it's been taught and then again like I said right
1:17:57
now we have this small window before Mass adoption where we can set defaults but in 5 years it's gone or three years
1:18:03
it's even gone because the technology proliferates incredibly quickly and it's incredibly impactful three five years
1:18:08
something like that all right Eric Schmidt said that he thinks AI will disempower the state and
1:18:15
so somewhere like China is probably more likely to be afraid of it do you think the AI disempowers the state or
1:18:22
emboldens the state to manipulate and control their
1:18:27
constituency I think that if you look at the State education healthare all these things it assumes ergodicity in humans
1:18:35
like a thousand toss of the coin is the same as a thousand coins toss at the same time because it can't customize to
1:18:41
us again we know people that go into government Healthcare education all these system they go in bright by bushy
1:18:47
tail and then the system grinds out of them it choose them can spits them out because it can't adapt to every
1:18:52
individual so if you think about again what should democracy be in an AI age it's representative democracy with s
1:18:58
assemblies AI kind of doing Dynamic policy work fully interrog by anyone and
1:19:03
adaptive right and then people using that technology to do better our systems
1:19:09
need an intelligence upgrade their slow d a eyes if we do that and again this is why we're going to build open government
1:19:15
systems and make them available to everyone both the building blocks and the end to end and inviting everyone to
1:19:21
contribute of course then that's the open infrastructure that we need otherwise what's going to happen is the
1:19:27
systems will be misaligned because people will just use these individual Tools in set to hyper Target because
1:19:33
they're not thinking about the longer term like how often do you think uh politics things what am I really here
1:19:39
for instead they just say that all of politics is who I owe and who owes
1:19:45
me in the China case the interesting thing is they don't want AGI because it
1:19:50
is a threat to their system the US wants AI China doesn't
1:19:55
want Ai and so many the discussions are rubbish I mean also stupid like China
1:20:01
has three of the world's five fastest supercomputers it can out build anyone it has more data than anyone because it
1:20:07
can use all the IP stuff and it can get all its citizens to just do data orentation it's also
1:20:14
silly the state in China like doesn't want AGI the AI will allow
1:20:21
it to expand more it'll probably be more controlling but does the average Chinese person mind if they've got economic
1:20:28
growth because a lot of these questions also come like are you growing or are you in the zero SU game and I can't tell
1:20:35
you if AI will be inflationary or deflationary at this point you know I can tell you that I can
1:20:40
see a part where it's got a far bigger economic impact than covid on the positive and the negative so we need to
1:20:47
build our systems to be able to respond to that and again we need to increase the agency of people to participate in that so I think it could go both ways
1:20:55
um and again this is why I think the next few years are so so vital because even if it stopped today it's still
1:21:01
happening right no more breakthroughs no more Q star star agentic Strawberry
1:21:06
Fields whatever what do you think religion's response is going to be to
1:21:12
AI um just talking the Vatican about Catholic AI so there'll be some models
1:21:18
trained to uh it allows again what's the purpose of religion it's community building it's spreading the word it's
1:21:24
kind of expansionary there my hope is that it will be better but again it
1:21:30
comes down to what's your optimization function I think that it does vary across religions though because you have
1:21:35
very top down ones and then you have religions like Sunni Islam for example that was based on um you have the
1:21:41
Eternal Word of the Quran temporal life of the prophet and then you interpolate between the two sometime around like the
1:21:47
13th century got too tough for people to do that with the oral tradition so you wrote everything down and then you went
1:21:54
from dynamic Juris prudence and F the oied one stuck in the 1th century
1:21:59
whereas now you can interrogate every single story of the prophet and the Quran with AI and so you can have
1:22:06
Dynamic FW reconstruction that shows all the Reasonable Doubt and things so I think that one gets an upgrade other
1:22:12
ones maybe don't they go the opposite way but again who knows it'll take a while for religion to get this
1:22:17
technology it's not exactly a POA maybe we'll get different religions more
1:22:22
religions like the outbreak of Cults and other splinters that we saw in the 70s
1:22:27
because one of the things I do think is that people want meaning and they're going to look for it wherever they can find it
1:22:34
right do you ever worry that we need hardship and that AI is going to
1:22:40
eliminate hardship and actually therefore create a problem well you mean the Star Trek
1:22:46
future versus the Star Wars future yeah that so I have a hypothesis that humans
1:22:52
can't be fulfilled unless they're working hard at something that matters to them and
1:22:57
others well like I said I like the Japanese coner if a guy do what you like do what you're good at and do what you believe you're adding value and then
1:23:04
you're generally going to be happy in the middle of that and not necessarily necessitates hardship but it necessitates progress right and it
1:23:11
necessitates self-belief um because again someone could be happy just cleaning
1:23:17
floors someone can be happy just painting a few hours a day and just spending time with their family I think
1:23:23
that humans are not continuously happy though we've each got our kind of own things but I don't think again there's
1:23:31
this hygiene level whereby we have enough food in the world to feed everyone there a coordination
1:23:37
issue you know we have enough to educ technology to educate everyone if we can
1:23:42
get everyone up to a level of universal basic intelligence Universal basic resources then like said
1:23:50
everything else is almost entertainment that enables the happiness but but if you're not fed if you're not
1:23:55
educated properly if you don't have the right Healthcare you're going to be
1:24:00
sad you know um I do think there is this additional thing though of like we make
1:24:05
our own hardships like you've got your you go to a marine cor and you go
1:24:11
through a hazing thing that binds people to together the sororities you know you basically choose to do a startup there
1:24:18
into the B and true glass because you're going to try and do something different I don't think AI will ever get to a point where you know like we're just
1:24:24
those fat guys in Wally I think humans will always try more but we'll have more tools of that
1:24:30
test you know just like you and I can call on more resources than Kings
1:24:36
previously we're very fortunate yeah but doesn't matter we're not going to stop because again it's
1:24:43
anical unless you're like super enlightened Buddha you're not going to be like happy and content just doing
1:24:48
literally nothing and staring at a wall right you'll be looking for that I I think on that I feel quite differently
1:24:55
than you so uh and maybe it just boils down to the simple difference in belief
1:25:00
that I do believe people have to work hard I think if they are cleaning floors and it's easy they will not be happy if
1:25:06
they're painting and they're not literally at the edge of their abilities where they get angry and throw some of
1:25:11
the paints away paintings away and that the few times where it comes together
1:25:17
then yes they can be happy but I think if if it comes easily they're not going
1:25:22
to be able to um appreciate it and so with AI if it really does come in and
1:25:28
make everything easy and simple it's Utopia world of abundance I think I
1:25:34
forget who said this quote I think they will start breaking things just to feel
1:25:39
like they matter again I mean I've got a different view
1:25:44
to that but then that begs the question maybe a 1984 Brave New World China
1:25:51
social credit score system with s and people being made happy and then those
1:25:57
who want to strive and go up being that maybe that's better I don't know I don't know who makes that decision like again
1:26:03
do the Chinese want an American star system the actual Chinese people right
1:26:09
probably not do the Americans want chines no they don't I think that it differs for different people around the
1:26:15
world but again I think there is something inherent in humans about kind of progress and the people at the edge CU I think everyone is on this spectrum
1:26:22
I think um himan wait but why refers to this everyone the spectrum of cooks
1:26:27
versus chefs and we all have that within us are you making the recipes and that's you striving that's you painting that's
1:26:33
you creating or you just following the recipes a lot of people are actually genuinely intent with following and this
1:26:41
is kind of again what we've seen throughout history like again I think your view of the world I don't think
1:26:47
many people are happy at all so surely the useful thing would be to make them happy by striving in a video game
1:26:54
economy with Soma and kind of other things because they'll be content and they'll be happy you lost me at Soma
1:27:00
Soma obviously is uh for people that don't know Brave New World you're numbing people out you're letting them
1:27:06
give into their hedonistic Pleasures that certainly as I think about building Virtual Worlds I think about the thing
1:27:13
that biologically we are driven to do uh and so no I wouldn't want things to be easy I would want things for people to
1:27:20
make progress you mentioned that earlier I think that's critically important but the key to the formulation that you laid
1:27:25
out that I think is so important eagy requires that you be doing something
1:27:31
that adds value and that's where I'm like I think people are going to struggle with that if AI is just making
1:27:38
all problems go away now humans have to find a way what is that thing that I can
1:27:44
do that other people actually think are valuable and that's where this gets
1:27:49
interesting well that's where you can delate it down to the community level so the Argentine and Fs program rather than
1:27:56
doing Universal basic income did Universal basic jobs and lots of women came into the economy on the localized
1:28:02
level where they tried it and the community would come up with jobs and context because again about video you
1:28:09
know their birth rate this was like couple of a decade ago or two oh man we're gonna need some
1:28:16
stats on that because if uh pulling women into the workforce implies that
1:28:22
that is how that Society is telling women that they can add value which hey
1:28:28
is one of the ways for sure love it the most my wife is an entrepreneur died in the wool hardcore no kids I get it but
1:28:36
at the same time that's horrendous for the birth rate well I think that again you can't
1:28:43
have everything at once and the key thing is having the opportunity right so I don't like Universal Bas
1:28:49
income because why because it's a hand out without meaning and I think that it can become
1:28:55
misallocated again when I look at the future I see two things one is you know we're working on a conceptualization of
1:29:01
universal basic intelligence where everyone has a series of AI things for free basically but then the more
1:29:07
valuable stuff you can work for shall we say but then also I think we will need to for example have a universal
1:29:12
Community Job Program whereby the community can Define its own value and its own jobs within that we may move to
1:29:19
a future in decades where we have no more money the existing systems about to break anyway but Max that on our credit
1:29:24
cards the Petro dollar Peg is gone and everything like that you need to Define meaning but meaning is defined almost
1:29:30
inter subjectively and localized as well so when I play a video game I have meaning within the context of the video
1:29:36
game and the rules and I feel progress like why do I like eldering why I just complete the DLC because you know beat
1:29:43
those blooming bosses and had lots of failure and it's a Growing Experience why it's incredibly popular made a
1:29:48
billion dollars right even though it's so challenging but we're wired that way in
1:29:55
that we need to have something to measure against to progress and that's why I said value but the value can be I
1:30:01
a good member of my congregation in church you know or it can be I'm very good at creating paintings or I'm very
1:30:08
good at my job I just think we have to be a bit more rigorous in the way that we do that and think about new ways to do that because
1:30:14
otherwise I'm that graduate and I've got a computer science degree and there's no programming
1:30:19
jobs and I lose my agency because a lot of this that I
1:30:24
think we're discussing again all comes down to I think a agents it's just agency can I do something do I have
1:30:33
control of my own destiny can I have value according to my own context system and can I progress
1:30:40
you know like again it's the story of the investment banker uh fisherman I
1:30:45
think do you know that one whereby banker and a fisherman no investment
1:30:50
banker like retired he goes and he meets fisherman coming back and you know he's
1:30:56
got a few fish he's like what are you doing it's like two like I'm going back to my family and I'm going to you know like um Grill these fish on the barbecue
1:31:02
and you know we're going to get together with some brand I know where this is headed like yeah you can go back and you
1:31:08
can like just do some more fishing and then you can use the proceeds to get a boat and then you know get more boats blah blah blah so what do I do at the
1:31:14
end of that well you can retire and you can go and you can do some fishing you can hang out with your family ET Etc again we all kind of at different points
1:31:20
of our lives have different measures be it grades be it Sports be it games other things that we measure ourselves against
1:31:26
and again this is where I think the AI balances can be so important because often we lose sight of what we actually
1:31:32
want to do like this is again I mentioned Clayton Christenson earlier I think he's got fantastic business
1:31:38
thinking he had a stroke Cancer and a heart attack whoa and then he came back from there he
1:31:45
lost the ability to speak and he wrote this book how will you measure your life because he was like schol mates with
1:31:51
just Skilling from Enron and all sorts of things of business knowledge but then also how many of us stop to think but at
1:31:57
the end of our Lives what will we measure ourselves against what's our progress what are our performance indicators right because we get caught
1:32:04
up in life all the time and so we kind of have localized Maxima we don't have broader Maxima and you might identify
1:32:11
that as by the time you're 18 you spent 95% of the time all time you spent with your family with your parents you know
1:32:18
probably 98% in some cases and what am I actually maximizing for what am I measuring against CU you can't manage
1:32:24
what you can't measure but again am I adding any value because the key reason that I think you're going to have you
1:32:31
have the protests that you have the lack of belief for the kids that you're talking about there crisis of mental
1:32:36
health I have no control of my own destiny I can't do anything I have no
1:32:42
value you know and I'm looking at social media and everyone's got value and they're showing value and I'm not
1:32:48
anything like them and I had this promise of this American dream or this social contract that just doesn't exist
1:32:55
anymore and why there nothing I can do about it once you believe you can do something about it then that changes
1:33:02
your entire perspective and it's crazy because any of us can okay I don't have talent in making food I can go and
1:33:11
convince a bunch of amazing chefs make a restaurant and pull it together and then we can do it but so can anyone else
1:33:17
listenting this but they won't you know because very few people do do that but
1:33:24
those who do can be successful there's always a fear of failure there's always a fear of can I even do that if you can't do it you can convince someone who
1:33:30
can I think increase agency you know have self-directing value systems be a
1:33:36
bit more intentional about how you do it use the AI to help that because you can help think through it these are the types of things I think may help but
1:33:43
it's not easy then and again actually one of the amazing things of this is that we have a lot of global problems
1:33:49
mental health climate this that birth rate they say I can finally push and tell to the edge but what we teach that
1:33:56
Ai and how we align it is going to be the most important thing and that isn't alignment for making sure it doesn't
1:34:02
kill all the humans I think that's maybe a data question other things we can do it is some of these things that you're
1:34:07
discussing right now and we have to build that intentionally as a society how do we avoid Black Mirror I want the
1:34:13
benefits of AI but I don't want to end up in this sort of emotional uncanny valley again as a video game developer I
1:34:20
think about this a lot I want to bring really rad things into my game like Elden ring where you really have a sense
1:34:27
of I made progress I accomplished something this was fun I get that it's just a game but it was just tremendously
1:34:33
enjoyable but there's a phenomenal episode of Black Mirror where the woman's I think fiance dies and um she's
1:34:41
able to get a robot with his AI in it it looks like him it talks like him it sounds like him but some part of her
1:34:49
know he's deeply comforting at first deeply comforting but some part of her
1:34:54
knows it's not him how do we escape that
1:34:59
I can get what I want which is my grandma back my grandpa my parents uh
1:35:05
lover that passed away whatever but it's not really them and so there is some
1:35:12
dark offkey note that's struck how how do we have our cake and eat it too imod
1:35:18
I think it's just against societal Norms where it's a dangerous Society I think some level of Regulation is needed
1:35:24
again the same with the Gat Mechanics for video games the loot box mechanics and more like what you just describe so
1:35:30
are you saying pass pass a law that doesn't let you bring your dead wife
1:35:35
back in robot form no because I think some people will want that and again but then the question is what's the
1:35:41
permission system because they should have give permission for something like that right these are things whereby
1:35:47
legislation and Society I think again needs to have just groups of talented
1:35:52
people that can can help inform and they can help adapt to that and there's a commonality of this because the dead
1:35:58
wife back dead husband back is same across everyone in the world potentially
1:36:03
the cost of building an AI that can replicate and again it will be available on WhatsApp video anything
1:36:11
to talk to you of a loved one who's about to pass away is probably going to be 100 bucks next
1:36:19
year 100 bucks that's insane and 50 sense per
1:36:24
million words they say and any language anywhere just need
1:36:29
some of their history and them to chat a little bit and I have the voice I have everything so this is moving so fast
1:36:35
with things like that which again that will have a real emotional impact you might find it discordant but someone
1:36:41
else might not and so again this is the thing where you know you want your libertarianism versus kind of other
1:36:46
stuff one of the most difficult things is again we're very privileged we grow up any where we have and then but we
1:36:53
also push through we have our own viewpoints in the world the reality is AI will be used differently by everyone
1:36:59
around the world and some people will use it to enslave some people will use it to emancipate right but it can't just be that there is
1:37:06
only a few choices you need to proliferate some of the choices and again we need to set some standards around this because these are really hard things like I'm they bringing back
1:37:13
loved ones I don't know how I feel about it but I don't think it's something we should legislate against but it's
1:37:19
something we should definitely look into the harms of right because I can see the posit positive and the negative and that
1:37:25
applies to so many uses of this technology because it reflects us and it's actually come from our collective
1:37:30
intelligence intet which again is kind of crazy we need better data sets and it
1:37:35
resonates which is the crazy thing again once you hear an AI whisper to you you
1:37:41
know with full emotion it's crazy once you see it I think the latest
1:37:47
video technology when you agree it's broken Through The Uncanny valy now whereby it's incredible you and I have
1:37:54
trained eyes like I would say until a couple of months ago I'd be like I see something
1:38:00
instantly that's the eye now I'm like can't like then I go and look yeah
1:38:08
and I can see some subtle things right but just again my fast thinking is like
1:38:13
I can't tell anymore so that's why I think we need to set standards around it we need to adapt we need to proliferate
1:38:18
those but then we also need to again allow for Liberty allow for use as long as doesn't infringe upon the rights of
1:38:26
others and that's really hard that's why we need to distribute
1:38:32
this intelligence we need an open distributed intelligent AI system and then we'll have the proprietary ones and
1:38:37
all these other ones too but it needs to exist with the best standards we can have so you can say what is the best way
1:38:42
to teach calculus shouldn't be taught all is another question right but that might
1:38:48
not be the way you teach it because of your local curricular but eventually we want to move our infrastructure of
1:38:54
thought towards an optimized thing we want to build a society OS and reconstruct it and this is the one
1:39:00
chance we get at that right and my view is that countries and communities that
1:39:06
Embrace this and take the best of our generalized common knowledge and these systems will perform those that don't
1:39:13
and so again if you set good standards that's huge potential for a incredibly positive view
1:39:20
of humanity where we can solve and coordinate to most of the problems that can adapt to all the bad
1:39:27
stuff again this OA Loop because we don't know what we don't know might emerge like it may be that there's an AI
1:39:34
that figures out how to hypnotize people what will you do when that
1:39:41
emerges and it's controlled it can be a foreign adversary it can be
1:39:48
Facebook how are we going to react to that like literally hypnosis no kind of works right Welcome To My
1:39:55
Nightmare but again these are we don't we need to build systems that are more robust self adapting and I think we can
1:40:01
only do that with AI what would you give them as your best argument for why AI is going to be
1:40:09
awesome um I think it depends on your framing but the most powerful thing I've
1:40:14
basically thought of is AI is like those really talented
1:40:20
graduate assistants that we wish we had but we can be sure of and what does that mean it means we can do things we can
1:40:26
never do before the very practical thing is we're all going to die right and it's probably going to be through some
1:40:31
sickness all of us know someone in our lives who've had cancer Alzheimer's
1:40:37
dementia one of these conditions you will have an AI in a year or two that
1:40:42
gives you comprehensive authoritative upto-date knowledge on these conditions through your journey and outperforms
1:40:49
human doctors on empathy and is available in every language from the medical side to you know how to talk to
1:40:55
your family mental health and more over the coming years that's something that could never been done before and that
1:41:01
will reduce human suffering because the loss of agency you feel when you get one of those diagnosis is insane right and
1:41:08
again like it's difficult to find the support you need that's just one small example and I think that once we have
1:41:14
that right framing we can think of many more examples where we just wish I wish I had some experts around me I wish I
1:41:19
had support I wish I had help in the digital and Physical Realm do you so uh I just wrote down small uh
1:41:28
if that's a small example which already sounds pretty insane what are some of the ways that you think Society will be
1:41:35
positively impacted as you think about those ripples away from just the individual what ends up happening to
1:41:43
society I think that the infrastructure of our society is based on text and
1:41:48
reports and bureaucracy if you think about something like us elections are coming up you know
1:41:54
it be a unpleasant time right having the ability to embed a intelligence and the
1:42:02
government to check every single policy and then make it relevant to you and explain it comprehensively will be
1:42:09
awesome for understanding candid positions but then also for going to the DMV and getting your driver's license
1:42:15
you know that will be automated in some number of years may take longer may take sooner depending on our capabilities but
1:42:21
every single one of the things that you find frustration about where there's this bee to report framework where
1:42:30
there's this idea the image video the barriers are being reduced for all of those the information will flow more
1:42:37
freely and again think about most of your frustrations in life it's like due to lack of agency it's due to
1:42:42
frustration over systems of information getting stuff done or access to information all those barriers will be
1:42:48
brought down by this technology having that role of again these talented everywhere and there's no part of
1:42:55
Information Society that doesn't impact so hopefully you know it'll help us reduce frustration increase flow
1:43:01
increase our you know fun quotients as well and maybe make things more
1:43:07
functional so that is when you talk about a grad student I think that is
1:43:14
something that's really clear for people that are in the quote unquote Elite bucket but for the average person how's
1:43:21
this going to impact them because I think the average person is panicking cuz they think about their job and they think this is going to be automated away
1:43:28
and it really might be and so if you were talking to somebody who you say oh it's like having a grad student in your
1:43:34
pocket they're like I I don't even know what that is I don't care about grad students um why is their life going to
1:43:39
be better well because they can do more you know this is the thing where why you've always had technology like spreadsheets
1:43:45
came it changed counting and other things but you know it created brand new drops the main conern that we've heard
1:43:52
we discussed this last year I think you know was can you create the new jobs quick enough but the reality is anyone
1:43:57
listening to this can do their more more effectively using this technology even if it's in the report writing phase
1:44:03
everyone has to write something or summarizing emails this technology start to seep in Siri will actually be useful
1:44:09
right like again if it's not a grad student it's a hire you know a junior hire you want
1:44:17
someone to help you and bringing that hire in will be impactful and they'll do
1:44:22
what it says on the table all these issues like hallucinations where the AI makes something up you know
1:44:28
all these issues about the AI going wonky they're being slowly ironed out and now you get these really reliable
1:44:34
partners that can work with you that's on the productivity side then there's the other side which is the creativity
1:44:39
side you useo use udio use mid Journey now you use grock's image generation but
1:44:45
you can never generate images like you can now and now video is coming you can make
1:44:51
music and it's one something making that instant you know just playing around with promps once you actually start to
1:44:57
apply yourself just like anything your creative capabilties have gone dramatically up now what does that mean
1:45:02
it means that as you're doing your job the question is if I had helpers how could I do my job better then you'll out
1:45:08
compete those that do not Embrace this technology because the pace of technological adoption is always slower
1:45:14
than you'd expect until it isn't and right now we're in this building phase where everyone's trying this technology
1:45:21
but the implementation will come in a few years you know but then it'll come as a wave so if you've got one two years
1:45:27
experience applying this technology to whatever your job is you know to make it more efficient to make yourself more
1:45:33
productive then you'll do better okay so let me give you what I
1:45:39
see is the the big problems that we're facing as a society today and let me
1:45:45
know if AI helps uh and if so how so right now I think people really feel the
1:45:50
sting of inflation prices skyrocketed during covid uh they have not come back
1:45:56
down people do not feel good at the grocery store aumer has 10% of the buying power that a boomer had at the
1:46:02
exact same age in their 20s um there's a a just Mental Health crisis in young
1:46:09
people parents rightly are freaking out they don't know what to do about it and I think a lot of people look at Ai and
1:46:17
go oh my God like this is just the the Tik Tok algorithm come to life it's going to suck my child into a black hole
1:46:24
this is not good EOD these are all bad things what do you say to that basket of
1:46:30
I just want to be able to pay for things I just want my kids to be okay how's AI gonna help there or is it
1:46:36
not well I think you know AI is a very broad thing so a Tik Tok AI is different to generative AI is different to
1:46:42
Facebook AI in some ways different to a Siri um it could be an incredibly
1:46:49
negative future you know these things are dangerous you see them hijack the minds of a generation and now it could
1:46:55
be amped but again like I said the the flip side there's the positive side like how could we use this positively so you
1:47:01
look at things like inflation inflation is a monetary phenomenon here whereby we're suffering the overhang for the
1:47:07
stimulus spending during Co which you know nobody knew how much we had to spend we didn't know if how people would
1:47:13
die and now it's the overhang from that so inflation started to come down a bit but buy he said buying poers decreased
1:47:20
in general because of this when you look at the components of inflation food and other things I think
1:47:26
that and you look at Ai and you think about massive numbers of graduates digital graduates entering the
1:47:34
workforce it's probably going to be deflationary but the question is can you
1:47:39
have the stuff you need for living that's your hygiene Factor you know the stuff you need not to otherother and in
1:47:45
fact I think I can't remember who said it there someone said there's only two types of things things that are living for living and entertainment but we've
1:47:50
got to get to that basic level first and having more efficient systems to organize things to remove bureaucracy to
1:47:57
remove this overhead could help with that it should be deflationary taking
1:48:02
apart bureaucracies doing these things there's a question of jobs and a question of let's say the American dream
1:48:10
like what is the American dream if you strive hard you work hard you can be successful I think part of this crisis
1:48:15
is given all the knocks that we've seen he said parents think about their kids if my kid tries hard can they be
1:48:20
successful particularly when the AI are coming you know like any I said at the start of last year in five years there are no
1:48:27
more programmers I should have added as we know it just like you know we grew up with the flash programmers flash was
1:48:33
programming you know and other things the nature will change like if you use Claude from anthropic right now you can
1:48:40
make games basic games like snake and others just by typing and telling it how to edit it and it will do it live right
1:48:46
there it's more proficient than most graduate programmers but that means the level of graduate programming has to increase so I think that when we look at
1:48:54
that this is the key worry is can we create the jobs in time or will it be enough of a demand response from The
1:49:01
increased amounts of entertainment and productivity to allow these kids to have careers and what will those look like
1:49:07
that's a really complicated question when I think about things like housing inflation others and monetary things I
1:49:14
think that it's deflationary and the cost of living right and the cost of organizing
1:49:19
right will drop and you know again these are very basic things like the fat in the US system you know like
1:49:25
how much does LA or San Francisco spend on homelessness it's over $100,000 per person per
1:49:31
year AI can easily deconstruct all that spending and Route it more appropriately when will that happen I know 5 10 years
1:49:38
out right but then you apply that to almost every part of living and you can see how it can make it more efficient
1:49:44
and more accessible but we've got these competing factors here whereby costs will come down but will'll demand catch
1:49:50
up and you know this opens up that question of do we need Ubi do we need Universal basic jobs do we need more
1:49:55
stimulus it all depends on the pace of adoption of this technology and how we deploy
1:50:01
it okay so we'll get to the the downside of it first but give me the the positive
1:50:07
look at this deployed well what does that look like what would we need to do
1:50:13
so integrating into the government that seems really smart not only so that I can or everybody can understand these
1:50:19
are the candidates these are the positions you know that bill that they dropped last night that you know is 1900 pages and it has to be voted on tomorrow
1:50:26
here's the summation here are the key points here are the things they trying to sneak in super helpful transparency
1:50:32
on budgeting super helpful um but what are other ways that you can see where if
1:50:40
we integrate this into society well that it drives cost down where people care
1:50:45
without triggering that existential crisis of well now what do I do as a human so I think if we look at regulated
1:50:54
sectors these are two very important ones like let's start with two things education and
1:51:01
Healthcare um you know after the recent I think Trump musk debate uh discussion
1:51:08
I think they said you know why even have a Department of Education in the US if educational outcomes are what they are
1:51:14
like kids graduating from school not being lectur is insane yeah right and what is school
1:51:20
it's Child Care mixed with a Cal State game mixed with a petri dish in many cases right the only thing that's been
1:51:26
proven to work in education is called the bloom effect two standard deviation Improvement outcomes is one to on
1:51:32
tuition sometime in the near future every single child should have their own personalized AI tutor that can tell are
1:51:41
they auditory are they visual Learners do they have dyslexia and adapt the curriculum to them and encourage them to
1:51:47
engage with others and increase their agency basically help them on the educational path
1:51:53
again one to one tuition has a two standard deviation Improvement it's the only thing that's proven to work in education really so something like that
1:52:00
could transform the education seor from an information going back and forth with the kids and again bringing the kids
1:52:06
together to do stuff now the question is who's going to build it you know and who's going to build it right and
1:52:12
implement it we'll come back to later so Healthcare is another one the average US life expectancy has been dropping but
1:52:20
everyone else has been increasing and saying is that the US spends more than the UK as a percentage of GDP on public
1:52:28
healthare yet you will have to have private healthcare as well and you UK Healthcare isn't bad
1:52:34
isn't great but again you don't have that Health that you deserve and ultimately it's your health that's going to get you your health impacts every
1:52:41
part of your life and ultimately we all will die what if we could reduce many of
1:52:46
these things and that again is your personal Healthcare body but also I think every medical diagnosis
1:52:53
has to be checked by AI before the diagnosis is made by AI it'll be malpractice not to have that and how
1:53:00
many lives could be saved we all know people that have had botch diagnosis botch this botch that you won't have
1:53:05
that with ai ai out performs human do on diagnosis as well as like say empathy so when you kind of look at all the sectors
1:53:12
that are regulated they usually regulated because they have a real human impact and much of the issue is information flow and personalization the
1:53:18
teacher cannot teach 30 kids at once because their attention is split the Align misaligned incentives and the
1:53:25
thing is we all know people who start and want to become teachers and doctors and in the government most of them start
1:53:32
with ideals and they have them beat them out out of them by the system right they can't reach everyone we see this again
1:53:37
and again and again this technology can change because you can have personalized information for every single individual
1:53:44
relevant to them and you can coordinate information as well our Collective knowledge so this
1:53:51
is where we should have all the cancer knowledge in the world comprehensively authoritatively and up to date available
1:53:56
to anyone at any time as a public good for example again that just needs to be built so I'd say those are the types of
1:54:02
areas the regulated Industries where you can have a transformation government education Healthcare and more and that's
1:54:08
again what you need for living then there's the other side which is entertainment which is we all know creatives and how much does it cost to
1:54:15
make a movie well it's getting smaller and smaller how much does it cost to make a video game how much does it cost
1:54:20
to tell you a story you know like Tik Tok was um one of the first indications where you know you're short doing short
1:54:27
clips right but we both I think agree in a few years you'll be able to make Hollywood length movies because movies
1:54:34
are just made of two and a half second shots now it might not just be type of prompt I don't think that's what we're
1:54:39
talking about we're talking about I want to tell a story I want the control over that we have the generative capabilities
1:54:44
that we can do that be it music be it movies be it more and again it can
1:54:50
transform because you're no longer constrained to to the medium like why should songs be 3 minutes long you know
1:54:55
like what is the appropriate way to tell a story is it Snippets is it large movie you can play around with it you can take
1:55:01
this podcast and translate it into a 100 languages now and it'll have your voice
1:55:06
and my voice but I think these are some of the things I've been thinking about like again that's just having a bigger
1:55:12
team around you and a team that's on your side when it comes to regulated industry and increase transparency
1:55:17
breaking down the barriers and like on the creative side it's building the tools that
1:55:23
remove the barriers to people telling those stories all right I'm going to look at
1:55:28
everything through an optimistic lens for now like I said again we'll we'll get to the darker sides of this um I'm
1:55:35
going to paint a picture this is what I actually think is going to happen but if you spot any naive elements in this uh
1:55:42
please Point them out because I really do want an accurate vision of the future more than just an exciting one um but
1:55:50
when I look out at the world there a few things that I see number one is the Health crisis you've already talked
1:55:55
about that I'm going to have something in my pocket that's going to help diagnose or if I've already been diagnosed by a standard physician that
1:56:02
it's keeping me a breast of all the research that's coming out that is unique or that applies to me it's going
1:56:08
to know my uh DNA it's going to know my microbiome so it will have a better understanding of how someone with my
1:56:13
makeup is going to metabolize a given drug and so is there a trial or something that I should be going after I
1:56:19
think that will be huge um I think the mental Health crisis is absolutely
1:56:25
massive and I think being able to help with that I think AI is going to be
1:56:30
tremendously advantageous because here's how I see it working you're going to be wearing devices that are taking a an
1:56:37
objective snapshot of your realtime physiology so where is your heart rate
1:56:42
it will detect a spike in anxiety how well are you sleeping what's your blood oxygen level all things that we can read
1:56:49
already but it's just so much data it becomes very difficult to correlate to a thing I just did or something that I saw
1:56:56
or encountered or what I ate which would be a huge part of this and it's tracking
1:57:02
this just incredibly multivariate thing and saying oh right now you just
1:57:08
encountered this thing it's triggering a stress response you need to relax or hey you've been relaxing too much you need
1:57:14
to push yourself um given the patterns that we've seen on the days you're more active or the days where your anxiety's
1:57:21
lower your depression is or whatever and use the biof feedback as a way to get
1:57:27
out of sort of the you know talk to me about it because I think that talk to me about it there's some question marks
1:57:33
around how um helpful that is depending on how your therapist is running the
1:57:38
session so therapy is one of those things I think can go very right and I think it can go very wrong so if we have
1:57:44
if we introduce the biological data into that feedback loop I think I think
1:57:49
things get a lot better uh and then uh education again you've already talked us
1:57:56
through that but that one toone curriculum I think is incredibly important and your AI being to being
1:58:02
able to flag for you where you're at are you ahead are you behind you've told it the things that you want to optimize for
1:58:09
in your life and it's like well you say you want to optimize for that but you're doing these things they don't really align with your goals what if you took
1:58:16
this course whatever and then the last one is and this might be the most important is all throughout history
1:58:24
every time that you get into a um very concentrated urban area which you can
1:58:30
read as a proxy for um safety stability in society the whole strong men make
1:58:37
good times good times make weak men that whole cycle um population declines
1:58:42
that's not only a modern phenomena that's happened over and over and over and when you look at the different um
1:58:49
population collapses they've always been tied to a precipitous drop in birth rate
1:58:54
which obviously we're seeing now just rapid beyond all measure uh especially
1:59:01
in South Korea Japan uh America's not doing great not doing it as badly but
1:59:06
you're seeing it in in a lot of places now my hope with the population collapse
1:59:14
is that um one just that AI can do all the things with health uh read into
1:59:21
goals in terms of helping steer people's behavior so that they want to have children that they can be on that track
1:59:26
that the AI can help them not be 36 and suddenly realize they want to do it but be advising them much earlier but
1:59:33
possibly more important and I'd love to get your take on uh this very specifically is Robotics and that as we
1:59:40
get this upside down pyramid of a ton of old people and not nearly enough young people to support them uh that robots
1:59:48
and or embodied AI if you will which is another way of saying robots uh will be able to step in and take care of that
1:59:55
burden so that not all bright minds of the Young Generation are sucked into elder care what do you think about that
2:00:02
is that any of that poana or does that true I think that a little reasonable
2:00:08
like I think the mental health one is a particularly interesting one because there's your biomarkers it's also your
2:00:15
voice you know you can tell a lot from a person by the way they're speaking and just picking up on that and again that's
2:00:21
what good therapist can do the AI can do that even better now we've got we've seen some research that'll be coming out soon about that being able to pick up
2:00:28
the Timber and also respond with the correct voice like there's a bit of a black
2:00:33
mirror is uh thing I've been thinking about recently you know whereby this is
2:00:38
the BBC show about dystopian views of the future I'm not sure that's a good thing or bad thing I'm not sure we
2:00:44
discussed it before given a few hours of discussion with someone I can recreate a
2:00:49
perfect loan of them in terms of voice reaction you can WhatsApp them you can call them you can even have zooms with
2:00:55
them now live and you won't be able to tell that sounds creepy but what if it is a loved one that's about to pass away
2:01:02
you know your grandma someone that you trust who's always looked out for you then imagine that person being with you
2:01:09
throughout and supporting you now that's simultaneously horrifying
2:01:14
and slightly comforting but it gives you an idea of kind of the stuff that is now possible because like I said you can
2:01:21
zoom with them you can text them you can call them maybe one day there'll be a robot is that positive for mental health
2:01:27
or negative it can be again be both ways this is a dual technology right but I think it reflects the fact that the AIS
2:01:33
that are coming there's a classical big data and we have this measured life with our fit bits and all of that right and a
2:01:40
lot of these Healthcare things are like dashboard based I can measure this and some of our brains accept for that but
2:01:47
then there's nothing like someone next to us telling us you're doing okay or you know shape up and we will put so
2:01:56
much trust in these AIS that are next to us because we have to remember as well you know this isn't a not like when you
2:02:04
look at the distribution of intelligence with intelligence is coming into the community now right they were building
2:02:10
artificial intelligences half of America half of the world is under 100 on IQ that's just
2:02:17
the way it is it's a normal distribution right
2:02:23
ouch now 95% of people think they're above I
2:02:28
IQ you know and in places where there's malnutrition it can be as low as 80 on average for Nations US states go from 95
2:02:35
to 105 on average but if you think about that like
2:02:40
many of us technologists we build for like people who've had very privileged
2:02:46
lives and we live in bubble right but if you think about 10 20 30 years from now
2:02:52
and many of these things it's like people didn't have the opportunity they didn't have the chance they've had malnutrition kind of bad backgrounds or
2:02:58
they just red with junk they don't believe all of a sudden like I think
2:03:03
anthropic did an IQ test on Claude it hit 100 but then it will also again be able
2:03:09
to speak to you in the most comforting voice in the world or tell you that you need to shape up or these other things
2:03:15
and so again when I think of mental health I see this range of things from recreating your grandma before they away
2:03:22
so you can always get their wisdom to I don't know like Aristotle who just your
2:03:27
own personality that grows with you and I don't think we've ever we' never even
2:03:33
be able to explore or conceive that technology right but again I know if someone I trust tells me to do something
2:03:40
I want to work hard for them and that's the most difficult thing again not these dashboards and these big data kind of
2:03:45
things it works for certain Quantified minds but nothing kind of Beats that kind word you know at the right time
2:03:52
time so this is why I think it will be huge for mental health for kind of feedback loops it could also
2:03:59
be incredibly dangerous you know but again we're doing the positive side of things there aren't enough people to support people that's why like I said
2:04:07
something like a loved one had a diagnosis of pancreatic cancer and so for a week I
2:04:13
thought she's going to die a thousand AI AG just analyze everything canc a 5% survival rate right and then turn out to
2:04:20
be a misdiagnosis after we build analysis but think about everyone who gets diagnosed with them the loss of
2:04:26
agency they feel there's not enough humans in the world to support appropriately but it should be a
2:04:32
combination of the AI helping and bringing the right humans to support you as well because again nothing beats real world
2:04:37
contact until you have robots I think again the embodied AIS the pace of
2:04:43
Robotics has leap frogged in the last year or two um there's a company in
2:04:48
China called unry they have a robot called the G1 have you seen that one
2:04:54
no so the G1 um is 5'2 34
2:04:59
kg and can run at four miles per hour it can make you an omelet and it's got uh
2:05:07
reinforcement learning so if one robot learns Kung Fu the other robots can learn Kung Fu as well and it's
2:05:15
$116,000 so you can look it up the unry G1 Elon mask reckons the Tesla Optimus
2:05:21
will be to $20,000 I reckon it will be as well and so right now they look a bit
2:05:26
weird but again they'll look more and more human they'll be able to speak human because I think you don't want to get this uncanny valley thing where you
2:05:32
got this plastic face but again we respond a lot to voice and you look at AI voices now they're perfect right but
2:05:39
you can't tell anymore with 11 labs and hen and other things like that again you can have your voice in 20 30 40
2:05:46
languages now your voice but in Spanish so but I look at that I'm
2:05:53
like there not this Blade Runner future where it's kind of Flesh Bots and everything I just think again robots will be there alongside us but there is
2:05:59
a difference again with this embodiedness just like you know we like our dogs and the kind of things like that but all of a sudden they've got a
2:06:06
level of Engagement is it sentience as AGI know but again they're there and they can communicate with you they can
2:06:12
be your brist they can do that they can do that and you said this kind of fixes the population pyramid and it's very
2:06:18
interesting that the place that will make the most robots is China right
2:06:23
which has why do you think they make the most 27% of the Chinese economy is
2:06:29
industry apart from they're the biggest industrial producer in the world where do most of the cars in the world come from
2:06:35
right uh there's 80 million cars and 70 million motorcycles built a year in a
2:06:41
few years I'm pretty sure the number of robots will get up to 100 million a year again it was $10,000
2:06:47
$20,000 put that another context when you look at the cost of you know you can look at like buying a car if you buy a
2:06:54
$10,000 car how much does it cost a lease a month like a 100
2:06:59
bucks for 100 bucks you will have a 5 foot6
2:07:05
robot that can do that can make you omelets or look at a recipe and then make it instantly that can learn from
2:07:11
other robots that has fine grain control like again when you look at unry G1 it
2:07:17
like it's got a coke bottle it flips its finger and the coke bottle app goes off you know that's the level of control
2:07:22
we've got now so this will be useful and we're seeing studies whereby you know
2:07:28
robots and personal assistance help the elderly like how much does the US spend
2:07:33
on Elder Care versus child care you know a lot more already and they said this is
2:07:38
coming we want to increase the population I think you know we've seen the studies around lack of testosterone
2:07:44
we've seen the studies around the hygiene factors of people not wanting to have kids they can't be sure about the
2:07:50
future we want to bring them but you know it's positive to have this but we
2:07:55
need help yeah and so if we can't find the human help we need to have digital help
2:08:02
and I get digital help that can talk to us of our level and understand us better than anyone and that's why we make sure
2:08:08
that's aligned it's physical help you know the embodied help around you that can help you physically with doing all
2:08:14
the tasks you might need but then also like going beyond that and again there's a shocking thing around the cost of all
2:08:20
of this right like it's $8 a month for Brock on
2:08:26
X and that includes a subscription to make as many images as you want and edit them and an AI That's like open AI
2:08:35
level it would have thought it'd be that cheap you know we're talking $100 a
2:08:40
month to lease a robot that can maybe do 95% of our human
2:08:46
who would have thought it' be that cheap and so again it opens up this massive world of support whereby you can
2:08:52
have as much support as you need because you're not limited like if I want to go and hire that personal trainer it costs
2:08:59
how much right human personal trainer will still be good but then the availability of therapists personal
2:09:05
trainers waiters other things goes up dramatically and again there are negatives for that and there needs to be
2:09:10
the economic response but for many things it is also a positive when you think again about I think the hygiene
2:09:17
factors of humanity the living factors and you know then you've got the flourishing factors
2:09:23
right if we can get the economy right if we can get meaning right and some of these other
2:09:30
things so how are entrepreneurs going to use this I know a lot of young people uh
2:09:36
beginning entrepreneurs they're going to want to know how they leverage this their advantage is there an opportunity for wealth creation is this just going
2:09:43
to come at all at once that um there'll be no competitive advantage or is there
2:09:50
a window here where people people can take advantage of this so you know started as a programmer
2:09:55
23 years ago I was writing directly assembler code so directly almost to the hardware then programming became about
2:10:02
these bundle libraries of like this is how you make an iPhone app template things like that you built up levels
2:10:09
from that still when you look at the banking system it runs on cobal and Fortran
2:10:14
which I believe were made in 1960s stuff takes time to upgrade people
2:10:20
don't want to include what are basically research models because this is still
2:10:25
research not engineering a lot of AI Cutting Edge stuff you don't want Cutting Edge for your education your
2:10:31
healthare your critical systems you want stuff that's tried and tested but like I said this will be both longer and
2:10:38
quicker than we expect quicker because we're already seeing it appear and it just seamlessly goes in and breaks down
2:10:43
these barriers longer because it's not going to go everywhere in society all at once because again you can't take the
2:10:49
risk you need you can't blame the AI right um but that transformation we remember
2:10:54
the do transformation you know we remember many of these Transformations just embracing this technology using
2:11:00
this technology and helping people with that is an amazing business doesn't matter which sector you're in you know
2:11:06
again the mental model is you know we wrote this piece how to think about AI where we go through some of these we
2:11:11
were like think about it like you discovered this new consonant of graduates that are specializing and how
2:11:16
you going to deploy that to your personal life your company country whatever but your company because it's so hard to find good people think about
2:11:24
things in terms of flows not files so right now we're outputting image or a
2:11:29
text but eventually be multi-step like that whole process of writing a report
2:11:35
and getting all the information in multiple steps we will be captured that flow you know or in images and video we
2:11:41
have this system called comy UI that we built at stability AI which I left a little while ago for a
2:11:48
company whereby when you input a prompt it captures it but then every single edit to that prompt that you do and
2:11:53
every single additional model you use for upscaling and then if I send you that file it reconstructs the whole flow so files to flows and the final kind of
2:12:01
point we make and again there's a lot more to it you can check it out on our Twitter substack um is just you're
2:12:07
moving from thinking about the world in terms of these autonomous agents that will just get rid of all human endeavor
2:12:12
to how can we make people more agentic so if you're an entrepreneur the best thing to do is like how can I help my
2:12:18
customer well all businesses are the cost is less than the value created so it's all about how can I help my
2:12:24
customer achieve more how could I do it myself we're already seeing you know many of the V uh
2:12:30
startups that I'm seeing and small companies they don't need to hire as many people for Content creation as they
2:12:37
used to before you know they're using some basic agent based system they're using basic AI to be able to iterate and
2:12:45
develop faster because I think there is a increase in reach so again
2:12:51
systems like hen like 11 Labs any podcast you do is you can make
2:12:57
it in how many many languages you want right that's an instant increase in reach who knows maybe this will be popular in India or China or whever
2:13:04
right there's an increase in velocity so ideation you know again for
2:13:09
entrepreneurs that's incredibly powerful because you can give it something like a Claude a set of principles like this is
2:13:16
my idea for a business and you analyze it according to Porter's five forces
2:13:22
or you know hey you're a Stanford NBA or Harvard NBA can you break it down for me
2:13:27
and then you can interrogate it and it'll just go back at you so the ideation phase is important what could go wrong with this idea I'm having a
2:13:35
problem like again just having a bud that kind of gets you and there's a cost decrease side things that you
2:13:40
classically employed had to find people for which is the most hard thing when you're entrepreneur because you're
2:13:47
unproven you can offload a lot of that to the AI or to people that use AI which I think is more important and so
2:13:54
you know that helps have more generalists I think um and again time to
2:14:00
Market Market size access and then quality of service all right walk me
2:14:05
through how this is actually going to happen so when I think about these um potential employees for somebody that
2:14:12
wants to use AI let's say you're going to staff your company up with 8 to 10 people uh you know all of them being AI
2:14:19
but you're going to want them the thetically to specialize so will it be just one AI is
2:14:26
capable of going in any direction so you just take off the shelf nine or 10 uh generic AIS and you say you you're in
2:14:32
charge of this or is it one Ai and you just say Okay do this task in this way
2:14:38
do this task in this way so on and so forth so we built the first models for
2:14:43
creation you know and again we've got to human level in these narrow Fields now we're creating these flows and design
2:14:49
patterns of jobs so you've got your liberal arts grad now they're specializing so off the shelf now you
2:14:56
look at something like intercom right which many of us have used for the chat responses you know the helps side that
2:15:02
thing on the bottom right that you click on and then you can chat uh intercom have changed their business model
2:15:07
introducing AI now so they have an AI agent that looks at all your previous answers and you actually only pay
2:15:12
intercom for every resolved query it's not even a subscription service anymore everything is just fascinating but
2:15:19
you're seeing call center work come now that again can be your entire customer support but when I say entire I don't
2:15:25
actually mean entire because a much better system is that you need to have a manager for the AIS we haven't developed
2:15:32
the AI manager yet so one person managing all these AIS and again they're getting increasing customized is quite a
2:15:38
lot but it doesn't mean that you can't have someone that you to solve the problem of customer service for my product and you to hire all these
2:15:45
customer service reps and you've actually got better outcomes according to the data that's been coming out already
2:15:51
you know you've got your sales Outreach and your sales call likely massively automated now services are popping out
2:15:56
for that including engaging you don't know it's an AI effectively whereas previously you had how many sales reps
2:16:02
for a lot of these things advertising SEO design you can expect a lot more from your designers now like there's a
2:16:08
minimum level of quality that's going up but again the designer probably going to be managing a series of AIS so I think
2:16:15
that we haven't moved we're moving up the level now from these generalized models these more Specialized Service is
2:16:22
but if you still need to have your managers I think managing these services and again a human in the loop just to
2:16:27
check because they're not quite good enough they'll break through to good enough but again the most difficult
2:16:33
thing as an entrepreneur as someone trying to make a difference is hiring the right people to support you in these
2:16:39
functions as you yourself move from a generalist to specialist building a team and these AIS and these systems
2:16:46
have flaws and issues which I think you still need human Loop but they're improving fast but again I think that's
2:16:51
the mental model that you need to have When approaching this what are the functional components of my business and
2:16:57
which of these Services can I introduce to have cheaper cost better experience
2:17:03
faster iteration right and that differs area to area if I
2:17:08
think about this as an entrepreneur the thing that immediately jumps to mind is if these are all pre-made I'm not going
2:17:14
to have an advantage you're going to help me lower my cost of doing a thing that I need to do so take customer
2:17:20
service if I'm the only one with a customer service Ai and it delivers better results I'm in a great position
2:17:26
if we all have customer service AI now it's neutral again unless I have control
2:17:33
over the knobs that allow me to make my AI customer service better so take
2:17:39
culture I can inject culture into my Ai and have a competitive advantage over my
2:17:45
competitors just because they don't uh for instance back at Quest we used to say if you call this up and said hey I
2:17:51
really want to get in shape what should I eat we would say chicken breast and broccoli now that was like at the time
2:17:57
everyone just thought that was crazy but it was this I won't say viral thing but it definitely caught on people were
2:18:03
talking about it because we didn't promote our own product we told people look we know where we fit in the dietary ecosystem you're better off eating Whole
2:18:09
Food whenever you can but if you want to snack then by all means have one of our bars and so that
2:18:16
mentality was an advantage but if I'm stuck with an agent that just handles
2:18:23
things in sort of a generic way I'm trapped how when will that level of
2:18:29
control be available where I can take something off the shelf so I don't have to create it but I can dial The Knobs in
2:18:35
a way that's unique only to me it's available right now again these are like
2:18:40
like said Lial out sprads shall we say you know they have a wide range but there's something called a context
2:18:47
window so that's the prompt that you type in most people when you type in like 50 100
2:18:52
words um opening eyes GPT when it first came out could
2:18:58
take 2,000 words Google's latest models can take two million words wow or videos or audio
2:19:06
all at once so you can inject entire training courses and your company Bible and books
2:19:15
that you've given about your company culture and like sessions and it will at inference time
2:19:22
the time when it runs and responds assimilate all of
2:19:29
that and that's crazy right like again you created a culture guide your
2:19:36
company you can put that in the prompt you don't need to fine tune a model even so the fine tuning is when
2:19:43
you put it in the model permanently and again like to give you an idea now where the costs have gone they dropped like
2:19:49
probably 500 times the latest uh Gemini flash model is I think 15 cents for a
2:19:57
million words of output and fine tuning is free previously it was like
2:20:04
$150 wow so and again you can have your entire culture handbook in there so like
2:20:11
customer service again it depends is this a distributional thing or is it a cost right and so businesses are
2:20:16
repeatable processes and like were you the first Ed bar in the market you know like I buy
2:20:23
bottled water there are many intangibles around brand around classical
2:20:28
products that once you really understand where your cost your distribution base is and these other
2:20:35
things that's where you apply the AI and again where is your Edge your Edge is ultimately in your engagement with the
2:20:41
people that think you're giving value and are paying for that whatever that might be you know like clayon
2:20:47
Christensen um I departed hard bual Professor came with disruptive innovation had this jobs to be done
2:20:53
model where he said any product is part of a job to be done the
2:20:58
McDonald's milkshake in the morning is uh quite thick because you're drinking it on the way to work in your car in
2:21:04
America whereas in the afternoon they make it thin and runny because your kid's drinking it and you don't want them to be sucking on it for too long
2:21:09
you know but he said that there's a functional a social and emotional component to any of these so again as we
2:21:15
look at the classical business theor and what's worked it hasn't changed it's just that we've got a new Workforce and
2:21:21
the workforce listens to instructions but how many people on this call have realized soorry this podcast
2:21:29
listening to it have realized that you can give 30,000 words of instruction to
2:21:35
a chat GPT that you should treat it just like a new hire you can list out all the
2:21:42
instructions and it'll follow them you know instead they just type in little bits and they're just like oh why isn't
2:21:47
it consistent in its response right now if you give it the consistent
2:21:53
context will it give you the same output every time you can make it give you exactly the same output every time so
2:21:58
open I just released this feature called Json output which is structured data 100% reliable output for
2:22:07
example so again that used to be 60% at the start of the year now you're
2:22:13
like was very inconsistent at the beginning same with the image creation
2:22:19
okay so um we've we've got a lot of cool things going on at the AI level a lot of it feels like it's not quite here but if
2:22:26
I lean into things that aren't quite here but that seem like they're coming around the corner uh Elon Musk with what
2:22:33
he's doing with neurolink uh I believe they already have two human patients when I look at the future of AI it seems
2:22:40
inevitable to me that to keep up with AI especially as it becomes embodied we are
2:22:46
going to have a choice uh and I think to not end up in a position where you have
2:22:51
something that just so outstrips your intelligence your ability to communicate your ability to perceive the world I
2:22:56
mean just absolutely get left in the dust no longer the dominant species on the planet uh you're going to have to
2:23:03
consider augmentation what do you think about what's going on at neuralink uh
2:23:08
could you see yourself in the future embracing it our phones are on neuralink
2:23:14
at the moment so the whole concept of neuralink was that you know we're having a
2:23:20
discussion right now we're exchanging information but it's like that much information what if I could jack myself
2:23:27
in and just almost communicate seemlessly all of the context at all times you would have better input and
2:23:33
output and again you said that's how you can compete with these AI because an AI that can accept a thousand words of
2:23:39
instruction is kind of human right an AI that can accept two million words of
2:23:45
instruction that's something we've never seen before because you look at the thing it's got like 99% accuracy as well
2:23:52
and again to give you some context on this you can upload an entire like season of a TV show and ask it to pull
2:23:58
out the funniest parts where your humor is defined by Seinfeld relevant to that and it will do
2:24:04
that in one go a human canot do that right without
2:24:10
like weeks of effort you can do your entire code based and show yourself debugging it a video and it will
2:24:16
interplate all of that so when we look at that that LEL of information like
2:24:22
bandwidth is you know one of the key components of neuralink right now it's being use for
2:24:28
people that having issues conveying information to their arms their legs you know getting out there because they're
2:24:34
paralyzed Etc but we're all kind of paralyzed in the information we input we output and by our own I think Elon
2:24:41
refers to it as limic systems like we get in our own way a lot like come on how many of you us are kind
2:24:48
of about achieving our potential so having a self-regulating system does it need to be invasive maybe maybe not
2:24:55
it's going to be insane the example I gave earlier was the voice kind of talking to you into your earpods as an example but what if it's stacked
2:25:02
directly into you it's standardized we're wearing glasses we will have augmented glasses from meta coming soon
2:25:09
that kind of do that I don't know if you've got the meta Ray bands they're kind of cool can record everything as you go but now you'll have the display
2:25:16
coming up we again our phones are augmenting I think it will be a number of years for various safety reasons and
2:25:23
others I don't think we need it to compete with the AIS but again we're
2:25:28
moving into this world of like a person with a phone is going to compete some without a phone it' be like
2:25:35
saying I don't want internet you know and again it's an information bandwidth and information
2:25:41
customization thing just like Twitter and Tik Tok are optimized for a phone
2:25:46
you'll have information that's optimized for brain computer interfaces
2:25:53
and maybe the first step of that is the voice in your ear customizing to exactly what you want to hear in the way that
2:25:58
you want to hear it do you have a base assumption about how humans and AI will interact that
2:26:04
makes you say that we won't necessarily need uh brain computer interface to compete with AI because that seems
2:26:11
self-evident to me that we either have an AI That's treating us kindly and just
2:26:16
telling us everything that we want uh but we are very much beneath them on the
2:26:21
intellectual food chain or we augment I don't other than genetic engineering I
2:26:27
don't see a way around the truth of that statement well it's like saying that you
2:26:32
know we can't out compete smarter people than us there people smarter than you and I right the're people more
2:26:38
accomplished than you and I I think they're just citizens in society how dare you OT not not not as Charming Tom not as
2:26:46
Charming obviously not yeah but look I think again my base assumption is
2:26:53
this will be augmenting technology um the ASI artificial super intelligence debate is kind of a different one and
2:26:59
again you view it differently in different parts of the world where you know someone like Japan it's very much AI alongside humans in the US it tends
2:27:05
to be more this AGI AI God concept you know and what's it going to do and we can't tell because we can't conceive
2:27:12
something that's that much smar than us you know um but the question is do we need to compete and that's again comes
2:27:19
back to how will you measure your life and what is you you believe in I mentioned
2:27:25
earlier how many people listening to this podcast believe in the American dream or the British dream or the French
2:27:30
Dream anymore you know what the governments are kind of promised us what is your goal in life some people it's Faith some
2:27:37
people it's patriotism some people want to build a business get money do you need to be plugged in to
2:27:44
compete if you can have the AI working with you for you maybe you work for I'm not sure like again most people just
2:27:50
happy being day to day and they just want to be happier within their individual context you know they don't
2:27:56
want to break the ceiling and Achieve massive great things you know and so
2:28:03
that's why I said like maybe we do need a few people that are jacked in you know
2:28:08
like overseers or something like that maybe we will end up like the Bor but happier hopefully you know because I the
2:28:15
Borg one of the main examples of this collected collective intelligence it's very doubtful that it'll be individual
2:28:22
intelligences right like if we're jacked in we're all jacked into the internet already on our social media we've
2:28:27
created some sort of weird hive mind with memes on there with new computer interface will be even worse but again
2:28:33
maybe it can damp our limic systems which CA us to do stupid things but
2:28:38
we're just not sure so I think you know what I focused on given the uncertainty is just let's make sure the technology
2:28:45
is as widely available distributed understandable as possible you this is why I open source AI by push governance
2:28:52
and some of these other things versus being controlled by a few people because what I do know is is incredibly
2:28:57
persuasive and if it's just a few entities having access to this technology it feels kind of undemocratic
2:29:03
given it'll affect us all you know I think that the brain computer interface staff is still a number of years away
2:29:09
invasive non-invasive but we're going to have plenty of examples of it influencing us on this individualized level again just
2:29:15
even via airpods way before that
2:29:21
okay so I'll take exception to the way that you're painting human nature I don't think the average person is happy
2:29:28
I think by Nature humans are a creature of pursuit um I think we are just
2:29:35
unrelenting wanting machines and
2:29:40
um we seek status and so given that we are an unrelenting wanting machine who
2:29:46
seeks status if we give birth to something that isn't like okay look there are people way
2:29:52
smarter than me and if I'm honest that bothers me and if I had a solution I
2:29:58
would take advantage of it now the people that are smarter than me are uh I
2:30:03
ran the math one time and I think Einstein was 2.6 times this is roughly correct if not exactly 2.6 times
2:30:10
somebody who meets the literal definition of a [ __ ] um that okay fair enough but once that
2:30:17
person is a hundred times smarter than you you a 100,000 times smarter than you a million times smarter than you all of
2:30:24
a sudden that's not as fun anymore and so do you really think that people won't
2:30:32
um augment themselves to keep up specifically yeah I don't think most
2:30:38
people are happy I think they're content not content but again they're just in their cycle shall we say let's take an
2:30:45
example maybe steroids steroids allow you to up very
2:30:50
quickly there are side effects there'll probably be side effects to neural computer interfaces at the start not
2:30:56
everyone that works out takes steroids even though there you know you go to the gym and there's all these buff people
2:31:02
there right I think it depends on societal acceptance it depends on again what you want to do daytoday there are
2:31:09
still people that issue like they don't watch Netflix they don't kind of do this kind of stuff they are not that
2:31:17
competitive the people that are competitive will want to compete and they want every single Advantage they could have but again I think that you're
2:31:23
at the top end of competitive relative again to the vast mass of people out there so there is this picture of which
2:31:31
all of humanity is upgraded with NE computer interfaces you know maybe it's Matrix one it's a vog one there aren't
2:31:37
that many positive versions of that right that I can think of um but again like I said for me your iPhone is the
2:31:44
first step of that right these are our digital assistant they are our brain computer interfaces the information is customized to us
2:31:50
but my guess is that again this will be a slow thing as opposed to a mass adoption thing where everyone's like oh
2:31:55
I must compete with this artificial super intelligence in fact I think what's going to end up happening is most
2:32:01
people welcome being all watched over by Machines of Loving Grace shall we say
2:32:06
like you look at senatorial confidence levels I think it's like around cockroach or something
2:32:12
like that not saying individual Senators aren't great please don't pull me up but we don't have faith in our politicians
2:32:18
anymore we' probably rather most people have ai systems you know and again this
2:32:23
is part of the issue that we'll be entrusting these systems a lot I don't mind smarter people looking after me shall we say and
2:32:32
if you look 100 years out we say like just way the on I'm just picking this I can't see more than 10 20 of course AI
2:32:40
is going to run everything you know what that looks like I don't know but it'll
2:32:45
definitely be able to run various things better than we can and what does that look like is an ASI
2:32:52
is it individual do there's probably going to be some level of human input just because you know just like you
2:32:58
listen to people anyway even if they say crap in your organization even if you make decisions um
2:33:05
like I I just don't think it'll be like I said this Mass B type thing with everyone competing to be at the top but
2:33:11
then maybe that's CL British not American as well it's interesting um
2:33:16
yeah I I am definitely far more competitive and so this could just be me projecting but when I look at if you
2:33:23
create an opportunity for something to be exploited humans will exploit it now you could be right that 98% of people
2:33:30
don't exploit it but it will be exploited even if it's only by the 2% and then suddenly you create this ever
2:33:37
escalating arms race all right before we get to that though let me ask there so there's one more final thing I'd like to
2:33:42
add to that yeah when we talk about Intelligence being 10 100 times larger we don't know if intelligence can scale
2:33:49
maybe it's just an S curve and you get up to like 300 and then it flattens out but it's probably going to be less about
2:33:56
intelligence more about not making mistakes you and I both are incredibly smart people and they tend to be a bit
2:34:01
unstable as we get smarter at the edges we get more unstable and there's actually many studies kind of showing
2:34:07
that just not making mistakes will make people far more effective than anything
2:34:12
like how many times have everyone on listening to this sabotage themselves right or made an emotional decision and
2:34:19
I will never never have to make an emotional decision and so maybe is that intelligence though or is it
2:34:26
execution so maybe the intelligence flattens out like already we're seeing saturation of these models in terms of
2:34:32
capabilities faing on ever more data with 10 100 times a thousand times more
2:34:38
compute but maybe execution you'll never be able to be an AI in execution and
2:34:43
reliability I think that's what you really want for yourself like you want to have all the information and the increased bandwidth but you don't want
2:34:48
to make the mistakes and again you want to learn from your mistakes you never kick yourself saying
2:34:56
well I did that because I was scared or I did that because of this you're like I did this completely rationally and I'm executing like a goddamn King you
2:35:03
know the interesting thing even if all AI does is have that ability to be
2:35:09
consistent to track their results to take in more points of data than humans uh they'll be able to do something that
2:35:15
I call the physics of Progress way better than humans so I think that there is simply a way that progress happens
2:35:22
that AI is is just going to be an ungodly Force at you come up with a hypothesis on how you think you move
2:35:29
towards your goal um you create the test that you're going to run to see whether that hypothesis is correct you identify
2:35:36
a metric that you think will improve uh in a very concrete term uh you run the
2:35:43
test and you assess the data to see did I actually make a meaningful move towards that yes or no uh if yes yes
2:35:49
cool keep doing more of that if no then reformulate hypothesis now with new data point and that's it it doesn't matter
2:35:56
what you're trying to do you're trying to improve your health you're trying to be a better parent you're trying to run a business that that is literally the
2:36:02
the physics of how you get ahead at something and the problem I find with
2:36:09
humans in that phase is they will often feel like a test is going to work and so
2:36:15
when they run the test they don't set a metric ahead of time that they think will be influenced and so no matter what result they get they're like yeah that's
2:36:21
what I was expecting so it's like cool the test was a success without really looking whether they made progress to
2:36:26
their goal or not or they lie to themselves uh this wasn't a poorly executed or poorly framed test this was
2:36:33
some external thing that stopped me that and it would have otherwise worked and that's one of the ways that I think AI
2:36:40
can create this just incredible um momentum by again being
2:36:47
able to take in way more data always assessing the situation as accurately as
2:36:52
it can be assessed and then adjusting accordingly and again this is kind of if
2:36:58
you treat it like a sparring buddy and you get it to check your output according to the rules you've set
2:37:05
yourself that'll be the most effective use of this AI at this moment in time we need
2:37:10
self-regulation you know we break our habits all the time and so this is why like again it's
2:37:16
execution machine like you know what we describe is the OA Loop in military terms right observe Orient decide and
2:37:22
act because you don't know kind of where you're going but then once it comes that it becomes about execution and am I following through
2:37:29
with what I said and I'm just keeping on top of this is everyone doing their job on their part the AI will not drop
2:37:35
something they won't get tired or lazy or forget to file something but again as you get to swarms of AI with
2:37:42
coordinators this is you can't beat an AI in execution you can't beat a robot an execution so I think that
2:37:50
again the act of intelligence has been somewhat conflated by this whole AGI
2:37:55
discussion where we're like trying to conceive of this Super Genius
2:38:00
breakthrough stuff but most of the world can just be changed through rigorous execution in fact that's how
2:38:07
the best companies are right the're machines where everyone knows their parts how the best teams work like you
2:38:13
know if you got a good functioning team the sum is greater than the whole
2:38:18
individual part right again I think it's the same with AI so maybe I that's where you'll feel the most competitive
2:38:24
pressure honestly it won't be the case of the AI is a genius so I must be a genius it will be I want to achieve to
2:38:32
my best potential like Limitless style right like that movie with Bradley Hooper and I want to suppress the stuff
2:38:40
that gets in the way on demand it's still being human that stuff but again this is what meditation is this is what
2:38:47
again Life Learning is this is what building our mental systems are it's just difficult to keep to them until
2:38:55
now if you had to place a bet is intelligence going to hit the S curve and stall
2:39:01
out I think so where do you think it stalls out
2:39:06
at um on IQ basis like 300 250 probably 300 300 I
2:39:12
imagine okay so right now we're at you said roughly 100 for Claude when it took
2:39:17
it 3x from here Einstein was if I'm not mistaken 260 or
2:39:23
265 think probably 200 on the standardized one but yeah maybe above
2:39:28
that so kind of above Ein you think it'll be substantively smarter than
2:39:34
Einstein be smart Einstein definitely Einstein made lots of mistakes again he's human right but
2:39:41
again it isn't inconceivable for an AI to be as smart as the smartest human but
2:39:48
you don't need to be all the time right like we're talking about
2:39:53
Einstein we're talking about his ability to synthesize and make breakthroughs but how many breakthroughs did he make
2:39:58
during his life or a uler or any of these other prodigies we're talking dozens not thousands or
2:40:04
millions and again we're thinking about this giant embodied AI That's trained on a million gpus when really again how
2:40:13
many breakthroughs do we need to change the world we need no breakthroughs to change the world we actually know what needs to be done to change the world
2:40:20
you don't need any more intelligence than you have here you need execution capabilities right when it comes to intelligence what are those
2:40:25
breakthroughs going to be in you know there's the competitive Zero Sum kind of thing which is I have a business insight
2:40:32
and then I go towards it but usually business insights are resource constraint right can I get the like how
2:40:39
many comp how much competition is there for hot tubs in your area or flooring there only ever be a few people and it's
2:40:45
already low price thing it'll always be a decent business right and massive economic collapse you get what I mean
2:40:51
right so there's always these pockets of value that you can find will the but these discussions of
2:40:57
AGI are like this giant Godlike AI that will have constant flashes of Brilliance
2:41:02
all the time I just don't think that doesn't kind of syn with me but being able to
2:41:08
burst to be as smart as a smart as human yeah but then being better in things like these massive context like Windows
2:41:15
in rigorous execution in ability to observe object l or in it actually I
2:41:21
think AIS will have very good intuition something we can kind of talk about because the previous generation
2:41:27
that because I don't I don't understand how an AI is going to develop intuition so the previous generation of
2:41:33
AI was Big Data massive amounts of data and extrapolation right this new generation of AI doesn't
2:41:41
do that you don't need these giant mainframes we take huge amounts of data so something like gupt 4 is probably 10
2:41:47
trillion words and the model itself is probably 20
2:41:53
gabt which is smaller than the archive of Wikipedia which is something like 10
2:41:59
million words it's insane what it does is it figures out the commonalities and
2:42:05
principles and context so when you put a piece of you put your an essay there
2:42:11
like your quarterly review for your investors right and you say make this a rrap in
2:42:18
the style of 80s hip hop Pac Shakur style whatever and it
2:42:23
will write it and you've seen that right it just does it instantly how does it know that it guesses the next word based on the
2:42:29
context of a Tac and 8s hip hop rock this that because it's embedded the
2:42:35
context of all of these and the meaning of it so like when you put the word cup in an image generator it's like there's
2:42:42
cup cup your ears cup your hands and you can see with the real time ones now because you can generate in real time
2:42:47
with some of them how the image changes d ially when you say cup your hand it do like that or cup of water it'll do the
2:42:54
cup of water and you can see this in things like um so what it do understands
2:43:01
context what do we do whether we into it we've built our mental models and we understand context there's a practical
2:43:06
example of this Tesla self-driving Tesla self-driving used to be 300,000 lines of
2:43:14
code now it's one of these what's called diffusion models so that's the same
2:43:19
technology we used when we devel the stable diffusion system that you know revolutionized the text image generation
2:43:25
and it's used now in these video models too where basically you take an image or a video whatever or like a video of you
2:43:33
driving like from the Tesla cameras you destroy it down to its smallest part
2:43:38
using a physics based process and then you reconstruct it and figure out how that process of reconstruction occurs
2:43:44
and in that you understand the context what self T of self-driving is basically doing is it's guessing what's coming
2:43:50
next it's intuiting why do you call it intuiting
2:43:55
so uh here's how I hold in my head what AI is doing it simply has uh been
2:44:02
trained on so many patterns it simply says when you say Tupac and wrap I now
2:44:07
create a subset in a database essentially and now I know okay what are the patterns within this now limited
2:44:13
source of my grand set of data cool here are the patterns and now I will just guess the most ly token that follows
2:44:21
that one and so it looks like it's coming up with words or intuiting something but in reality it's just saying oh you want me to find the
2:44:27
patterns in the subset of data here they are and so that hearing you talk about
2:44:32
this it sounds like and now I'm going to put words in your mouth and so push back and tell me this doesn't make any sense
2:44:38
but if I lead with oh emod thinks that AI is conscious then okay you think that
2:44:44
it has a subconscious process which is how I would Define intuition intu inition to me is an embodied sub
2:44:51
literally below the conscious mind sense of ooh some parts of my body have picked
2:44:57
up on a pattern that I have not consciously picked up on uh that does not seem analogous to what's happening
2:45:04
with AI to me well I think AI is subconscious but it's not conscious so
2:45:09
when you look at an AI model again what is a model it is a file like an MP3 or
2:45:16
MP4 or whatever like a photo there is no logical process of code if
2:45:22
this than that it's like a SE we push words in we get an image out so if you look at exactly the data that you would
2:45:29
have to make an intuition that isn't involving your higher Vortex your trade of thought
2:45:35
reasoning brain and you look at an AI as it stands as generative AI gen AI is
2:45:42
doing the intuition is doing you it's type one versus type two thinking that Aran a psychologist who very famous just
2:45:49
who did this book thinking fast and slow one type of thinking is my very logical thinking you know that's slow thought
2:45:56
reasoning yeah fast as intuition slow as logic there's a
2:46:01
freaking yeah tiger in the wood I see that small outline right or I think I in
2:46:08
it that this is probably the most likely way to go forward based on all my experience and my training so you can take a model and you
2:46:15
can like a generalized um driving model and you can train it on the pool roads
2:46:21
and then it will get better at driving on the pool roads and for me that's a type of again subconscious intuition where it's guessing based on context the
2:46:27
next thing and again you can fit the context window with as much information as you would have when making an
2:46:34
intuition but the AI is probably going to in it better than
2:46:39
you like I kind of know what say Barbie
2:46:44
Oppenheimer movie poster will look like just go to grock right now you type in Barbie opheim the post it it'll make one
2:46:51
right but that isn't a conscious Chain of Thought reasoning decision it is a string of words Barbie Oppenheimer
2:46:59
poster by Paramount going into this blob of Weights The Blob of
2:47:07
ones and zeros This MP3 file this picture file and out the other side is generated an image it's not doing any
2:47:13
logical thinking now within that there are weights and there's balances and probability right but again it's not
2:47:20
looking up a database or structure or creating anything intermediate and that's just like again
2:47:26
our brains where we build up our neural networks and we can have information coming in this fast thinking and into it
2:47:31
what kind of comes next you can just respond react and that's why self-driving works and again test of
2:47:37
self-driving uses this technology it's kind of guessing what's coming next and
2:47:43
in some studies again it's outperforming human drivers and you know the driver sense
2:47:48
that you have when you're sporting something there was a study done recently that showed that we can detect
2:47:54
our breast cancer five years before it occurs you know and you think about a
2:47:59
top radiologist they say I think something's wrong I dig and they'll do that I just do that now so I would say
2:48:05
that all AI is doing now is fast thinking and that's why one of the biggest challenges now and why we're introducing new technology is actually
2:48:11
the slow thinking and AI so fast that we haven't slowed down so as you get to customer
2:48:16
service agents and all this other stuff and these I'm talking about that's where Chain of Thought reasoning and other things are actually active research
2:48:22
topics we're trying to figure out how to make it less intuitive slower
2:48:30
ironically and more thorough in its thinking so if we can combine the two what do we
2:48:36
have yeah that will be uh extremely interesting to see if those problems can
2:48:43
be solved now is that key to your thinking on how we get 3x smarter AI
2:48:49
than where we are now and if so how do we train it like what if we've already
2:48:55
run through everything that's available on the internet how do we actually make this thing 3x smarter well we're training on junk
2:49:02
still so the internet is junk um right now we've seen some
2:49:07
studies like um there's this Microsoft model called thi where we just generated
2:49:12
textbooks and we just fed it with textbooks but then when we added a s Le
2:49:19
of the snapshot of Internet the performance got better and for me that's a bit like well it's a brook versus
2:49:26
someone who lives in the real world right like if you already ever trade on textbooks but we don't know the food that these AIS need but we're getting
2:49:33
better at understanding that so when we made stable diffusion we needed two billion images we capture on the
2:49:40
internet two billion images we excluded watermarked images and gy and all that someone achieved the same
2:49:47
performance on 25 million I'm seeing which parts of the neural
2:49:52
network got lit up by the most common qu you could throw out 99% of the data and again if you
2:50:00
think of it like a liberal arts gr what's the curriculum we need to feed it better data and then it'll get better
2:50:06
but then what's the feedback loops for it to recursively self-improve so Apple intelligence has just arrived on your
2:50:12
smartphone with apple intelligence now it's a three billion parameters so like a probably
2:50:19
fp4 2 to 3 gigabyte file and then it has these adapters called luras for
2:50:26
individual topic areas so it's got a generalized intelligence and specific areas intelligence for like note taking
2:50:31
and other things and it swaps out like the training courses for the AI where the AI kind of switches that out soon it
2:50:38
will have the ability to recursively self-learn and adapt to you so it'll be able to train on device based on its
2:50:44
understanding of you just like you go to some of these image sites and then you can train your face in and hey you got a Tom model you
2:50:51
know and now you're an astronaut and you're a dog and whatever right so the next step is we go from
2:50:57
these base models that in it to recursive fine-tuning
2:51:03
adaptation increasing automatic generation of context which is the instructions and then what's happening
2:51:09
now in the iere there's this massive focus on what's known as Monte Carlo Tre search for a gentic
2:51:15
AI so Monte Carlo Tre search is the type of AI that was used to have an AI that
2:51:22
could beat humans at Dota 2 or alphago you know so playing computer game type
2:51:29
AI where you gave it the rules of a computer game and then it played against
2:51:34
itself and then it beat humans and we've seen it kind of playing arbitrary games Atari games Nez games
2:51:41
kind of everything that kind of died down a little bit because no one really wants to get beaten by nii all the time
2:51:47
it's kind of annoying right um and again the interfaces of this was slowed down it wasn't like the computer
2:51:53
being directly jacked into a video game like it had to like almost manually human wise respond to things and things
2:51:59
like that right and learn on the flight it wasn't thr all the games of history but it just got better and better and
2:52:05
better then you had this deep learning phase where it was all about training these giant models and giant data but
2:52:10
again we haven't optimized the data and now it's about the recursive self-improvement so we've seen recently
2:52:16
a slew of things that can write academic p papers they do it by breaking it down hypothesizing testing and having
2:52:22
different models try different things and again that reflects normal society normal teams and more so this is the
2:52:28
next wave of recursive self-improving AIS should come next year that self-correct their faults that
2:52:36
LE um and that is what gets us up to this 300
2:52:42
double but most of the time you don't want 300 you know like again 100 is
2:52:48
enough well I don't know that I agree with that but why will recursive
2:52:54
self-improvement stop at 300 I don't see why that has St well
2:53:00
because you max out the score tests effectively and again what is intelligence like the ability to solve
2:53:08
novel problems how many novel problems do you have to
2:53:14
live oh I mean okay so you and I might have to Define ter here uh so the thing
2:53:21
that will make AI truly just World
2:53:26
shatteringly different it is going to terraform the way that we live no matter
2:53:31
what already just the way that it's headed much like the internet uh but for to really break free and and have the
2:53:38
shot at Utopia or quite frankly dystopia uh to me it has to be able to have
2:53:44
breakthroughs that humans have never had so my current understanding of AI is it's just a pattern recognition
2:53:52
machine which means unless there is a pattern that is right in front of our faces that none of us have seen it's not
2:53:59
going to share human experiences by crawling the net reading all of our books watching us move about the world
2:54:05
and suddenly go oh you're missing this pattern I I don't think that's ever going to happen now what it will be able
2:54:11
to do whether it can have breakthroughs or not is taken a lot more data than we can so it can see cancer 5 years early
2:54:19
uh simply because there there is a complex Confluence of things but it's
2:54:24
still just recognizing a pattern uh for it to have a breakthrough on the order of Einstein I don't know what that is
2:54:32
that strikes me as magical in a human uh I wouldn't know what to even look for in
2:54:38
an AI but that feels very different like you're not going to get there from recursive self-improvement so anyway
2:54:43
that when I talk about intelligence I'm talking about that there is hey we need to bend SpaceTime so that we can travel
2:54:50
to a distant star that is a very novel problem and we as humans have been
2:54:55
unable to do that because we cannot understand the mathematics uh or maybe the substrate that that we exist in but
2:55:02
there's some key thing that we're missing so I mean look science builds
2:55:08
upon previous things and occasionally there breakthroughs that happen simultaneously right like um you have
2:55:14
breakthroughs like information Theory you have breakthroughs in Mater matal sciences and
2:55:21
more I think if you kind of look at the ability of AI to synthesize and build
2:55:26
again I give the I just told you that we can make a poster of barban Oppenheimer made by Paramount and it'll be generated
2:55:33
in a few seconds you don't even Flinch right that doesn't exist in the data set
2:55:38
you know but that's I'll argue that I'll argue that so and I'm open to being convinced that I'm not trying to be a
2:55:44
contrarian but here's uh the reason that you can do a Bobby Oppenheimer Barbie
2:55:51
Oppenheimer poster is because they both have identifiable explainable what I'll
2:55:57
call looks which is simply a visual uh Motif that Motif is simply a pattern so
2:56:02
these are all more fancy words for patterns so Barbie has a pattern from color palette to angle choice to um type
2:56:10
of character way they're posed hairstyle all of that that's what makes her Barbie uh and then same with Oppenheimer right
2:56:16
so and you could do give me a Barbie Oppenheimer poster in the style of The Simpsons because those all have an
2:56:24
identifiable what I'll call a mimical uh style this is why you can do an
2:56:29
impression of somebody uh because there are things that they do that when you
2:56:34
repeat those patterns the brain suddenly goes oh that's how Trump talks right that's why you can do an impression of
2:56:39
trump so what I'm saying is yeah AI is always going to be able to do anything
2:56:45
that I can break down into a pattern and it's cool and it's amazing but that that is not how Einstein figured out his
2:56:52
theories they weren't pattern related well so this is where it is
2:57:01
instinctively use that word inductively like the AI can make Barbie Oppenheimer
2:57:07
and we just take it for granted now right and again it's got patterns and it Mees the patterns it Mees the Styles
2:57:13
recently uh Deep Mind released a paper on their new AI model that
2:57:18
blind look to International math Olympiad papers so this is the competition where the smartest
2:57:25
mathematicians um university just before University get together and solve these papers and it's called the
2:57:31
silver utilizing this agent based self-recursive learning system because
2:57:37
to solve these problems they're really hard you know you get easier they're not the hardest problems in the world but
2:57:43
with actually not that much computation it could solve these denovo problems that aren't in the data that require
2:57:49
inductive reasoning they require an understanding of the precepts of mathematics and open eyes indicated they
2:57:56
have a gold um and one of the things here is the amount of compute that we
2:58:01
put into solving these things is actually relatively minimal we put in this much compute to training the models
2:58:08
but then we make the models consumer grade so gp4 can pretty much run on a
2:58:16
MacBook a giant memory MacBook yeah what if we created models
2:58:23
and millions of agents that used as much energy as we used for that the more energy you put into solving a problem
2:58:30
especially a new one well the more likely you are to solve it in some ways especially if you
2:58:35
can always remember every single try that you did in the different ways that you do it uh Terren to is one of the
2:58:42
best mathematicians of the generation he's like super genius he now uses AI
2:58:48
every day as a partner to help him figure out new math
2:58:53
H know how he's going about that I'm very curious to know what he did to like
2:58:59
surely he's not just working with gp4 has he created a custom model is there something he had to do to
2:59:05
it he is using gp4 he's just giving all of his assumptions and using the context
2:59:12
length and getting the feedback and trying and experiment to with new things because there's no one that he can just talk to like that
2:59:19
but it can think through a few layers of this big picture stuff but he again he's got his own capability he just needs to
2:59:25
have a sparring partner right but gpc4 we' heard talk about this new thing qar
2:59:31
or strawberry from open AI that has the agentic workpl everyone's building it it
2:59:36
will be able to remember it will be able to improve it will be able to you'll be able to put as much compute budget as
2:59:43
you want against solving a problem just like you add Manpower but where we add
2:59:48
manpow what happens if you put a dozen scientists in a room nothing because
2:59:54
they're all opinionated and they have egos and everything like that n of these AIS have
2:59:59
egos and so the first step is this intuition as it were like you know the bar on par as I call it or this context
3:00:06
shift or this pattern matching then there's the inductive reasoning the thinking slow and when you start
3:00:12
combining these and again you allow it to take time there's software piece of software called
3:00:19
so normally when you use GitHub copilot this code software it does things instantly
3:00:25
right Devon you tell it to B as an iPhone app and it'll go away for seven hours or eight hours and run dozens of
3:00:33
these queries and this is before agents and start building it and checking all the different bits because as an example Barby
3:00:40
Oppenheimer okay now we just generate it and it might work it might not work the future is go and make Barbie Oppenheimer
3:00:48
say well I kind of know what F likes and what the context of this is generate an image check it for consistency you know
3:00:54
then check it for proof reading check it for color palette optimization there'll be an entire flow of knowledge and again
3:01:01
this is where the future for getting to that super intelligence or you know this 300 IQ will be needed for certain things
3:01:09
where you're making new recipes and new breakthroughs I think probably the main contention or the main difference in
3:01:15
context you and me is that I'm thinking a lot about the AI that will will be used around the world and there'll be
3:01:20
some of these 300 iqis but the vast majority will be 110 120 that's all we need you know and
3:01:27
again there'll be execution machines um so again I think that this
3:01:32
is a required step to get there because we've just modeled one part of the brain so far and we have to combine it with
3:01:38
all the other parts of the brain and then we have to combine it with the smartest people in the world working
3:01:43
together because the learn genius is one thing but amazing teams are far more
3:01:49
likely to get stuff done and again we can add infinite technically now there's no
3:01:56
limit on the amount of context we can put into the context window these models um someone's figured that out and
3:02:02
there's no limit to the amount of energy we can put like what if we just spent as much energy solving a particular like on
3:02:10
Fast and light travel as a gp4 right now we wouldn't get there but maybe in 5 10 years you will right fundamental
3:02:19
of physics analyzed in depth in every single physics paper and again that kind
3:02:24
of thing you said talk all right if we've got people that are using Chad gb4
3:02:30
or equivalent to do things like uh help them identify new math it's far more
3:02:37
complex than anything I've been able to use it for that tells me I don't understand the context window well enough what is the key to a really
3:02:46
effective context window it's treating out like you were your
3:02:51
assistant or your buddy that you're sparring with intellectually right it's giving the instructions and
3:02:59
iterating and improving it so you know when you give instructions to the new
3:03:04
person you hired they have to understand the context of the thing they're doing the way that you work you know they
3:03:11
learn about the feedback and so you have to give it that feedback but again this is usually short context stuff most
3:03:18
people use chat GPT or anthropic Claude or Gemini with this very small amount of
3:03:25
data and again you can give it 50 give it 50,000 words or a million words of
3:03:31
instructions so again like someone like Terence to he uses it not for the
3:03:38
breakthroughs why would I Rely Upon a graduate or new high for a breakthrough right I'm the experienced one with all
3:03:44
the context and performing at the top of my game I'm using it to offload thoughts and to
3:03:51
have things bounce back and it will follow my instructions to give it back and maybe it will int it some stuff
3:03:56
maybe it'll explore and kind of look at this in five different ways right and
3:04:01
it's getting better and better at doing that and we see that in the statistics of the performance of these
3:04:07
models like CLA 3.5 the latest anthropic model is one of the first models I've
3:04:12
actually enjoyed using since the very early days so I think I'll catch up and now it's called out but again I using it
3:04:19
as a programming body better than any graduate programmer that I've worked with you know but before that it was
3:04:26
kind of crap but this experience is not going to stop getting better particularly because it's almost
3:04:32
too cheap now but rather than having again you might used to cost5 $150 for a million words and now
3:04:40
it costs 15 cents but those million words have got from 80 IQ to over 100
3:04:49
now oh the irony emot it is so fun to bounce these ideas back and forth with
3:04:55
you man thank you so much for taking the time where can people connect with you yeah you can follow the Twitter or
3:05:02
shingi that's all we love I love it all right everybody as
3:05:08
the Chinese curse goes may you live in interesting times and you certainly live in interesting times all right speaking
3:05:15
of interesting if you haven't already be sure to subscribe and until next time my friends be legendary take care peace if
3:05:22
you like this conversation check out this episode to learn more we have two Futures in our world today either a Mad
3:05:28
Max future or a Star Trek future do you think that as we transition over to AI
3:05:34
that it will take us through a valley of Despair or is this going to be a straight line to Utopia oh no big
3:05:40
valleys of chaotic despair